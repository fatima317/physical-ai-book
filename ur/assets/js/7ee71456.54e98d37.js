"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[7789],{2628:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"quarter-overview/module-4-ai-planning/index","title":"Module 4 - VLA Implementation","description":"This module covers Vision-Language-Action (VLA) systems and LLM-to-action pipelines for autonomous robotics, including navigation and autonomous systems integration.","source":"@site/docs/quarter-overview/module-4-ai-planning/index.mdx","sourceDirName":"quarter-overview/module-4-ai-planning","slug":"/quarter-overview/module-4-ai-planning/","permalink":"/physical-ai-book/ur/docs/quarter-overview/module-4-ai-planning/","draft":false,"unlisted":false,"editUrl":"https://github.com/fatima317/physical-ai-book/tree/main/docs/quarter-overview/module-4-ai-planning/index.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Module 4 - VLA Implementation"},"sidebar":"tutorialSidebar","previous":{"title":"Module 3 - NVIDIA Isaac Platform","permalink":"/physical-ai-book/ur/docs/quarter-overview/module-3-perception/"},"next":{"title":"Why Physical AI Matters","permalink":"/physical-ai-book/ur/docs/why-physical-ai/"}}');var s=i(4848),a=i(8453),o=i(5251),r=i(9105);const l={sidebar_position:4,title:"Module 4 - VLA Implementation"},c="Module 4: VLA Implementation",d={},m=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Topics Covered",id:"topics-covered",level:2},{value:"VLA System Architecture",id:"vla-system-architecture",level:2},{value:"Key Components",id:"key-components",level:3},{value:"Code Snippets",id:"code-snippets",level:2},{value:"VLA Implementation Example",id:"vla-implementation-example",level:3},{value:"ROS 2 Action Server for VLA",id:"ros-2-action-server-for-vla",level:3},{value:"Whisper Integration for Voice Commands",id:"whisper-integration-for-voice-commands",level:3},{value:"URDF Examples",id:"urdf-examples",level:2},{value:"Robot with VLA Capabilities",id:"robot-with-vla-capabilities",level:3},{value:"VLA System Diagram",id:"vla-system-diagram",level:2},{value:"VLA Implementation Pipeline",id:"vla-implementation-pipeline",level:2},{value:"Key Terms",id:"key-terms",level:2},{value:"Learning Checkpoints",id:"learning-checkpoints",level:2},{value:"Quiz Questions",id:"quiz-questions",level:3},{value:"Practical Exercise",id:"practical-exercise",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Personalization",id:"personalization",level:2},{value:"Translation",id:"translation",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"module-4-vla-implementation",children:"Module 4: VLA Implementation"})}),"\n",(0,s.jsx)(n.p,{children:"This module covers Vision-Language-Action (VLA) systems and LLM-to-action pipelines for autonomous robotics, including navigation and autonomous systems integration."}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"After completing this module, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Implement Vision-Language-Action (VLA) systems for robotics"}),"\n",(0,s.jsx)(n.li,{children:"Create LLM-to-action pipelines with Whisper integration"}),"\n",(0,s.jsx)(n.li,{children:"Develop navigation systems using ROS 2 navigation stack"}),"\n",(0,s.jsx)(n.li,{children:"Integrate autonomous systems components"}),"\n",(0,s.jsx)(n.li,{children:"Apply machine learning techniques to robotics planning"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Completion of previous modules"}),"\n",(0,s.jsx)(n.li,{children:"Understanding of basic AI and machine learning concepts"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"topics-covered",children:"Topics Covered"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Vision-Language-Action (VLA) Systems"}),"\n",(0,s.jsx)(n.li,{children:"AI Planning Systems"}),"\n",(0,s.jsx)(n.li,{children:"LLM-to-Action Pipelines with Whisper"}),"\n",(0,s.jsx)(n.li,{children:"Advanced Navigation Techniques"}),"\n",(0,s.jsx)(n.li,{children:"Autonomous Systems Integration"}),"\n",(0,s.jsx)(n.li,{children:"Voice Command Processing"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"vla-system-architecture",children:"VLA System Architecture"}),"\n",(0,s.jsx)(n.p,{children:"Vision-Language-Action (VLA) systems represent the next generation of embodied AI, where vision, language, and action are unified in a single neural architecture."}),"\n",(0,s.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Visual Encoder"}),": Processes visual input (images, video)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Language Encoder"}),": Processes natural language commands"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action Decoder"}),": Generates robot actions based on vision-language fusion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory System"}),": Maintains state and context across interactions"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"code-snippets",children:"Code Snippets"}),"\n",(0,s.jsx)(n.h3,{id:"vla-implementation-example",children:"VLA Implementation Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import torch\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModel\nimport openai\n\nclass VLASystem:\n    def __init__(self):\n        # Initialize vision encoder\n        self.vision_encoder = self.load_vision_model()\n\n        # Initialize language encoder\n        self.language_encoder = AutoModel.from_pretrained("bert-base-uncased")\n        self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")\n\n        # Initialize action decoder\n        self.action_decoder = self.build_action_network()\n\n        # Memory system\n        self.memory_buffer = []\n        self.context_window = 10\n\n    def load_vision_model(self):\n        # Load pre-trained vision model (e.g., ResNet, ViT)\n        import torchvision.models as models\n        vision_model = models.resnet50(pretrained=True)\n        # Remove final classification layer\n        vision_model.fc = torch.nn.Identity()\n        return vision_model\n\n    def build_action_network(self):\n        # Simple MLP for action prediction\n        return torch.nn.Sequential(\n            torch.nn.Linear(1024 + 768, 512),  # vision_features + language_features\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, 256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256, 6)  # 6DOF action space\n        )\n\n    def encode_visual_input(self, image_tensor):\n        """Encode visual input to feature vector"""\n        with torch.no_grad():\n            features = self.vision_encoder(image_tensor)\n        return features\n\n    def encode_language_input(self, text_command):\n        """Encode language command to feature vector"""\n        inputs = self.tokenizer(text_command, return_tensors="pt", padding=True)\n        with torch.no_grad():\n            outputs = self.language_encoder(**inputs)\n            # Use [CLS] token representation\n            features = outputs.last_hidden_state[:, 0, :]\n        return features\n\n    def plan_action(self, visual_features, language_features):\n        """Fuse vision and language to predict action"""\n        # Concatenate vision and language features\n        fused_features = torch.cat([visual_features, language_features], dim=-1)\n\n        # Predict action\n        action = self.action_decoder(fused_features)\n        return action\n\n    def process_command(self, image, command):\n        """Process vision-language input and generate action"""\n        # Encode inputs\n        visual_features = self.encode_visual_input(image)\n        language_features = self.encode_language_input(command)\n\n        # Plan action\n        action = self.plan_action(visual_features, language_features)\n\n        # Store in memory\n        self.memory_buffer.append({\n            \'image\': image,\n            \'command\': command,\n            \'action\': action\n        })\n\n        # Keep memory window size\n        if len(self.memory_buffer) > self.context_window:\n            self.memory_buffer.pop(0)\n\n        return action\n'})}),"\n",(0,s.jsx)(n.h3,{id:"ros-2-action-server-for-vla",children:"ROS 2 Action Server for VLA"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.action import ActionServer\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nfrom cv_bridge import CvBridge\n\nfrom vla_interfaces.action import ExecuteCommand  # Custom action\n\nclass VLAActionServer(Node):\n    def __init__(self):\n        super().__init__(\'vla_action_server\')\n\n        # Initialize VLA system\n        self.vla_system = VLASystem()\n        self.bridge = CvBridge()\n\n        # Subscribe to camera feed\n        self.image_sub = self.create_subscription(\n            Image,\n            \'camera/image_raw\',\n            self.image_callback,\n            10\n        )\n\n        # Action server\n        self._action_server = ActionServer(\n            self,\n            ExecuteCommand,\n            \'execute_vla_command\',\n            self.execute_callback\n        )\n\n        # Store latest image\n        self.latest_image = None\n\n    def image_callback(self, msg):\n        """Store latest image from camera"""\n        self.latest_image = msg\n\n    def execute_callback(self, goal_handle):\n        """Execute VLA command"""\n        self.get_logger().info(f\'Executing command: {goal_handle.request.command}\')\n\n        if self.latest_image is None:\n            goal_handle.abort()\n            result = ExecuteCommand.Result()\n            result.success = False\n            result.message = \'No image received\'\n            return result\n\n        # Convert ROS image to tensor\n        cv_image = self.bridge.imgmsg_to_cv2(self.latest_image, "bgr8")\n        image_tensor = torch.from_numpy(cv_image).permute(2, 0, 1).unsqueeze(0).float()\n\n        # Process command\n        action = self.vla_system.process_command(image_tensor, goal_handle.request.command)\n\n        # Execute action (send to robot)\n        self.execute_robot_action(action)\n\n        # Complete goal\n        goal_handle.succeed()\n        result = ExecuteCommand.Result()\n        result.success = True\n        result.message = f\'Executed command: {goal_handle.request.command}\'\n        return result\n\n    def execute_robot_action(self, action_tensor):\n        """Send action to robot"""\n        cmd_vel = Twist()\n        action = action_tensor.cpu().numpy()[0]\n\n        # Map action to velocity commands\n        cmd_vel.linear.x = action[0]  # forward/backward\n        cmd_vel.linear.y = action[1]  # left/right\n        cmd_vel.angular.z = action[2]  # rotation\n\n        # Publish command\n        cmd_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\n        cmd_pub.publish(cmd_vel)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    vla_server = VLAActionServer()\n\n    try:\n        rclpy.spin(vla_server)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        vla_server.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"whisper-integration-for-voice-commands",children:"Whisper Integration for Voice Commands"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import whisper\nimport speech_recognition as sr\nimport threading\nimport queue\n\nclass VoiceCommandProcessor:\n    def __init__(self):\n        # Load Whisper model\n        self.whisper_model = whisper.load_model("base.en")\n        self.recognizer = sr.Recognizer()\n        self.microphone = sr.Microphone()\n\n        # Adjust for ambient noise\n        with self.microphone as source:\n            self.recognizer.adjust_for_ambient_noise(source)\n\n        # Command queue for processing\n        self.command_queue = queue.Queue()\n\n        # Start listening thread\n        self.listening_thread = threading.Thread(target=self.listen_continuously)\n        self.listening_thread.daemon = True\n        self.listening_thread.start()\n\n    def listen_continuously(self):\n        """Continuously listen for voice commands"""\n        with self.microphone as source:\n            while True:\n                try:\n                    # Listen for audio\n                    audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=5)\n\n                    # Transcribe using Whisper\n                    transcription = self.transcribe_audio(audio)\n\n                    if transcription:\n                        self.command_queue.put(transcription)\n\n                except sr.WaitTimeoutError:\n                    # Continue listening\n                    continue\n                except Exception as e:\n                    self.get_logger().error(f\'Error in voice processing: {e}\')\n                    continue\n\n    def transcribe_audio(self, audio):\n        """Transcribe audio using Whisper"""\n        # Save audio to temporary file\n        with open(\'/tmp/temp_audio.wav\', \'wb\') as f:\n            f.write(audio.get_wav_data())\n\n        # Transcribe with Whisper\n        result = self.whisper_model.transcribe(\'/tmp/temp_audio.wav\')\n        return result[\'text\']\n\n    def get_next_command(self):\n        """Get next command from queue"""\n        try:\n            return self.command_queue.get_nowait()\n        except queue.Empty:\n            return None\n'})}),"\n",(0,s.jsx)(n.h2,{id:"urdf-examples",children:"URDF Examples"}),"\n",(0,s.jsx)(n.h3,{id:"robot-with-vla-capabilities",children:"Robot with VLA Capabilities"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="vla_robot">\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.5 0.3 0.15"/>\n      </geometry>\n      <material name="light_grey">\n        <color rgba="0.7 0.7 0.7 1.0"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.5 0.3 0.15"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.01" ixy="0.0" ixz="0.0" iyy="0.01" iyz="0.0" izz="0.01"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Camera Mount --\x3e\n  <joint name="camera_mount_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_link"/>\n    <origin xyz="0.15 0.0 0.1" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- Microphone Mount --\x3e\n  <joint name="microphone_mount_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="microphone_link"/>\n    <origin xyz="0.1 0.0 0.15" rpy="0 0 0"/>\n  </joint>\n\n  <link name="microphone_link">\n    <visual>\n      <geometry>\n        <cylinder radius="0.01" length="0.02"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- VLA Controller --\x3e\n  <gazebo reference="base_link">\n    <plugin name="vla_controller" filename="libvla_controller.so">\n      <command_topic>execute_vla_command</command_topic>\n      <image_topic>camera/image_raw</image_topic>\n      <audio_topic>audio_commands</audio_topic>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Camera Sensor --\x3e\n  <gazebo reference="camera_link">\n    <sensor name="camera" type="camera">\n      <always_on>true</always_on>\n      <update_rate>30</update_rate>\n      <camera>\n        <horizontal_fov>1.047</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>10</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <frame_name>camera_link</frame_name>\n        <topic_name>camera/image_raw</topic_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- Audio Sensor (Simulated) --\x3e\n  <gazebo reference="microphone_link">\n    <sensor name="microphone" type="gpu_lidar">\n      <always_on>true</always_on>\n      <update_rate>10</update_rate>\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>1</samples>\n            <resolution>1</resolution>\n            <min_angle>0</min_angle>\n            <max_angle>0</max_angle>\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.1</min>\n          <max>1.0</max>\n          <resolution>0.01</resolution>\n        </range>\n      </ray>\n      <plugin name="audio_controller" filename="libgazebo_ros_audio_device.so">\n        <frame_name>microphone_link</frame_name>\n        <topic_name>audio_commands</topic_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n</robot>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"vla-system-diagram",children:"VLA System Diagram"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[Human Speech] --\x3e B[Whisper ASR]\n    B --\x3e C[Natural Language Command]\n    D[Camera Feed] --\x3e E[Visual Encoder]\n    E --\x3e F[Visual Features]\n    C --\x3e G[Language Encoder]\n    G --\x3e H[Language Features]\n    F --\x3e I[Fusion Layer]\n    H --\x3e I\n    I --\x3e J[Action Decoder]\n    J --\x3e K[Robot Actions]\n    K --\x3e L[Environment]\n    L --\x3e D\n\n    style A fill:#ff9999\n    style D fill:#ff9999\n    style K fill:#99ff99\n    style L fill:#99ccff\n"})}),"\n",(0,s.jsx)(n.h2,{id:"vla-implementation-pipeline",children:"VLA Implementation Pipeline"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Stage"}),(0,s.jsx)(n.th,{children:"Component"}),(0,s.jsx)(n.th,{children:"Input"}),(0,s.jsx)(n.th,{children:"Output"}),(0,s.jsx)(n.th,{children:"Purpose"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"Vision Encoder"}),(0,s.jsx)(n.td,{children:"RGB Image"}),(0,s.jsx)(n.td,{children:"Visual Features"}),(0,s.jsx)(n.td,{children:"Extract spatial information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"Language Encoder"}),(0,s.jsx)(n.td,{children:"Natural Language"}),(0,s.jsx)(n.td,{children:"Linguistic Features"}),(0,s.jsx)(n.td,{children:"Extract semantic meaning"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"Fusion Layer"}),(0,s.jsx)(n.td,{children:"Visual + Language"}),(0,s.jsx)(n.td,{children:"Unified Representation"}),(0,s.jsx)(n.td,{children:"Combine modalities"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"Action Decoder"}),(0,s.jsx)(n.td,{children:"Unified Features"}),(0,s.jsx)(n.td,{children:"Robot Actions"}),(0,s.jsx)(n.td,{children:"Generate executable commands"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"Execution"}),(0,s.jsx)(n.td,{children:"Robot Actions"}),(0,s.jsx)(n.td,{children:"Physical Motion"}),(0,s.jsx)(n.td,{children:"Execute in environment"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VLA"}),": Vision-Language-Action - unified system for embodied AI"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ASR"}),": Automatic Speech Recognition - converting speech to text"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Vision Encoder"}),": Neural network processing visual input"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Language Encoder"}),": Neural network processing linguistic input"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fusion Layer"}),": Combines different modalities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Embodied AI"}),": AI systems interacting with physical world"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action Space"}),": Set of possible robot actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multimodal"}),": Using multiple sensory modalities"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"learning-checkpoints",children:"Learning Checkpoints"}),"\n",(0,s.jsx)(n.h3,{id:"quiz-questions",children:"Quiz Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"What are the three main components of a VLA system?"}),"\n",(0,s.jsx)(n.li,{children:"Name the advantages of unified VLA systems over separate vision, language, and action systems."}),"\n",(0,s.jsx)(n.li,{children:"How does the fusion layer contribute to VLA performance?"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,s.jsx)(n.p,{children:"Implement a simple VLA system that takes an image and natural language command as input and generates a basic navigation action (move forward, turn left, etc.)."}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,s.jsx)(n.p,{children:"Create a complete VLA pipeline that integrates with ROS 2, including:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Camera input processing"}),"\n",(0,s.jsx)(n.li,{children:"Voice command recognition"}),"\n",(0,s.jsx)(n.li,{children:"VLA action generation"}),"\n",(0,s.jsx)(n.li,{children:"Robot control execution"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"personalization",children:"Personalization"}),"\n",(0,s.jsxs)("div",{className:"personalization-options",children:[(0,s.jsx)("h3",{children:"Adjust Learning Path:"}),(0,s.jsx)("button",{onClick:()=>setDifficulty("beginner"),children:"Beginner"}),(0,s.jsx)("button",{onClick:()=>setDifficulty("intermediate"),children:"Intermediate"}),(0,s.jsx)("button",{onClick:()=>setDifficulty("advanced"),children:"Advanced"})]}),"\n",(0,s.jsx)(n.h2,{id:"translation",children:"Translation"}),"\n",(0,s.jsx)("div",{className:"translation-controls",children:(0,s.jsx)("button",{onClick:()=>translateToUrdu(),children:"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u062a\u0631\u062c\u0645\u06c1 \u06a9\u0631\u06cc\u06ba"})}),"\n",(0,s.jsx)(o.A,{}),"\n",(0,s.jsx)(r.A,{})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},5251:(e,n,i)=>{i.d(n,{A:()=>r});var t=i(6540),s=i(8478),a=i(4848);const o=({children:e,skillLevel:n="beginner",userSkillLevel:i="beginner",difficultyAdjustment:s=0})=>{const[o,r]=(0,t.useState)(e),[l,c]=(0,t.useState)({skillLevel:i,difficultyAdjustment:s});(0,t.useEffect)(()=>{let i=e;l.skillLevel!==n&&(i=d(i,l.skillLevel,n)),0!==l.difficultyAdjustment&&(i=m(i,l.difficultyAdjustment)),r(i)},[e,l,n]);const d=(e,n,i)=>{let t=e;return"beginner"===n&&"beginner"!==i?t=u(t):"advanced"===n&&"advanced"!==i&&(t=h(t)),t},m=(e,n)=>e,u=e=>e,h=e=>e;return(0,a.jsxs)("div",{className:"personalize-chapter",children:[(0,a.jsxs)("div",{className:"personalization-controls",children:[(0,a.jsxs)("div",{className:"control-group",children:[(0,a.jsx)("label",{htmlFor:"skill-level",children:"Your Skill Level:"}),(0,a.jsxs)("select",{id:"skill-level",value:l.skillLevel,onChange:e=>{return n=e.target.value,void c(e=>({...e,skillLevel:n}));var n},children:[(0,a.jsx)("option",{value:"beginner",children:"Beginner"}),(0,a.jsx)("option",{value:"intermediate",children:"Intermediate"}),(0,a.jsx)("option",{value:"advanced",children:"Advanced"})]})]}),(0,a.jsxs)("div",{className:"control-group",children:[(0,a.jsx)("label",{htmlFor:"difficulty",children:"Difficulty Preference:"}),(0,a.jsxs)("select",{id:"difficulty",value:l.difficultyAdjustment,onChange:e=>{return n=Number(e.target.value),void c(e=>({...e,difficultyAdjustment:n}));var n},children:[(0,a.jsx)("option",{value:-1,children:"Easier"}),(0,a.jsx)("option",{value:0,children:"Default"}),(0,a.jsx)("option",{value:1,children:"More Challenging"})]})]})]}),(0,a.jsx)("div",{className:"personalized-content",children:o})]})},r=e=>(0,a.jsx)(s.A,{children:()=>(0,a.jsx)(o,{...e})})},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var t=i(6540);const s={},a=t.createContext(s);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:n},e.children)}},8478:(e,n,i)=>{i.d(n,{A:()=>a});i(6540);var t=i(2303),s=i(4848);function a({children:e,fallback:n}){return(0,t.A)()?(0,s.jsx)(s.Fragment,{children:e?.()}):n??null}},9105:(e,n,i)=>{i.d(n,{A:()=>r});var t=i(6540),s=i(8478),a=i(4848);const o=({children:e,enableTranslation:n=!0,autoTranslate:i=!1})=>{const[s,o]=(0,t.useState)(e),[r,l]=(0,t.useState)(i),[c,d]=(0,t.useState)(!1),m={introduction:"\u062a\u0639\u0627\u0631\u0641",robotics:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633","artificial intelligence":"\u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a",ai:"\u0645\u0630","machine learning":"\u0645\u0634\u06cc\u0646 \u0644\u0631\u0646\u0646\u06af","deep learning":"\u06af\u06c1\u0631\u0627\u0626\u06cc \u0633\u06cc\u06a9\u06be\u0646\u0627","neural network":"\u0646\u06cc\u0648\u0631\u0644 \u0646\u06cc\u0679 \u0648\u0631\u06a9",algorithm:"\u0627\u0644\u06af\u0648\u0631\u062a\u06be\u0645",programming:"\u067e\u0631\u0648\u06af\u0631\u0627\u0645\u0646\u06af",code:"\u06a9\u0648\u0688",function:"\u0641\u0646\u06a9\u0634\u0646",variable:"\u0645\u062a\u063a\u06cc\u0631",loop:"\u0644\u0648\u067e",condition:"\u062d\u0627\u0644\u062a",robot:"\u0631\u0648\u0628\u0648\u0679",sensor:"\u0633\u06cc\u0646\u0633\u0631",actuator:"\u0627\u06cc\u06a9\u0686\u0648\u0627\u06cc\u0679\u0631",motor:"\u0645\u0648\u0679\u0631",controller:"\u06a9\u0646\u0679\u0631\u0648\u0644\u0631",navigation:"\u0646\u06cc\u0648\u06cc\u06af\u06cc\u0634\u0646",perception:"\u0627\u062f\u0631\u0627\u06a9",planning:"\u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc",execution:"\u0639\u0645\u0644",simulation:"\u0633\u06cc\u0645\u0648\u0644\u06cc\u0634\u0646",gazebo:"\u06af\u0632\u06cc\u0628\u0648",ros:"ROS","ros 2":"ROS 2",humble:"Humbe",jetson:"\u062c\u06cc\u0679\u0633\u0646",nx:"\u0627\u06cc\u0646 \u0627\u06cc\u06a9\u0633",nvidia:"\u0627\u06cc\u0646 \u0648\u06cc\u0688\u06cc\u0627",hardware:"\u06c1\u0627\u0631\u0688 \u0648\u06cc\u0626\u0631",software:"\u0633\u0627\u0641\u0679 \u0648\u06cc\u0626\u0631",development:"\u062a\u0639\u0645\u06cc\u0631","development environment":"\u062a\u0639\u0645\u06cc\u0631 \u06a9\u0627 \u0645\u0627\u062d\u0648\u0644",environment:"\u0645\u0627\u062d\u0648\u0644",learning:"\u0633\u06cc\u06a9\u06be\u0646\u0627",module:"\u0645\u0627\u0688\u06cc\u0648\u0644",chapter:"\u0628\u0627\u0628",section:"\u062d\u0635\u06c1",topic:"\u0645\u0648\u0636\u0648\u0639",concept:"\u062a\u0635\u0648\u0631",example:"\u0645\u062b\u0627\u0644",exercise:"\u0648\u0631\u06a9\u0634\u0627\u067e",practice:"\u0645\u0634\u0642",skill:"\u0645\u06c1\u0627\u0631\u062a",beginner:"\u0627\u0628\u062a\u062f\u0627\u0626\u06cc",intermediate:"\u062f\u0631\u0645\u06cc\u0627\u0646\u06c1",advanced:"\u0627\u0639\u0644\u06cc\u0670",difficulty:"\u0645\u0634\u06a9\u0644",level:"\u0633\u0637\u062d",progress:"\u067e\u06cc\u0634\u0631\u0641\u062a",completion:"\u0645\u06a9\u0645\u0644 \u06c1\u0648\u0646\u0627",completed:"\u0645\u06a9\u0645\u0644",understanding:"\u0633\u0645\u062c\u06be",comprehension:"\u0627\u062f\u0631\u0627\u06a9",knowledge:"\u0639\u0644\u0645",expert:"\u0645\u0627\u06c1\u0631",subagent:"\u0633\u0628 \u0627\u06cc\u062c\u0646\u0679",assistant:"\u0645\u062f\u062f\u06af\u0627\u0631",help:"\u0645\u062f\u062f",guide:"\u0631\u0627\u06c1 \u0646\u0645\u0627",tutorial:"\u0633\u06cc\u06a9\u06be\u0646\u06d2 \u06a9\u0627 \u0637\u0631\u06cc\u0642\u06c1",documentation:"\u062f\u0633\u062a\u0627\u0648\u06cc\u0632\u0627\u062a",reference:"\u062d\u0648\u0627\u0644\u06c1",resource:"\u0648\u0633\u0627\u0626\u0644",tool:"\u0627\u0648\u0632\u0627\u0631",framework:"\u0686\u0648\u06a9\u06be\u0679",library:"\u0644\u0627\u0626\u0628\u0631\u06cc\u0631\u06cc",package:"\u067e\u06cc\u06a9\u06cc\u062c",dependency:"\u0648\u0627\u0628\u0633\u062a\u06af\u06cc",installation:"\u062a\u0646\u0635\u06cc\u0628",setup:"\u0633\u06cc\u0679 \u0627\u067e",configuration:"\u062a\u0634\u06a9\u06cc\u0644",validation:"\u062a\u0648\u062b\u06cc\u0642",verification:"\u062a\u0648\u062b\u06cc\u0642",test:"\u0679\u06cc\u0633\u0679",testing:"\u0679\u06cc\u0633\u0679\u0646\u06af",debug:"\u0688\u06cc\u0628\u06af",debugging:"\u0688\u06cc\u0628\u06af\u0646\u06af",error:"\u063a\u0644\u0637\u06cc",bug:"\u0628\u06af",fix:"\u0679\u06be\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba",solution:"\u062d\u0644",problem:"\u0645\u0633\u0626\u0644\u06c1",challenge:"\u0686\u06cc\u0644\u0646\u062c",task:"\u06a9\u0627\u0645",project:"\u067e\u0631\u0648\u062c\u06cc\u06a9\u0679",application:"\u0627\u0637\u0644\u0627\u0642\u06cc\u06c1",implementation:"\u0646\u0627\u0641\u0630 \u06a9\u0631\u0646\u0627","real-world":"\u062d\u0642\u06cc\u0642\u06cc \u062f\u0646\u06cc\u0627",practical:"\u0639\u0645\u0644\u06cc",theory:"\u0646\u0638\u0631\u06cc\u06c1",practice:"\u0645\u0634\u0642","hands-on":"\u06c1\u0627\u062a\u06be\u0648\u06ba \u0633\u06d2",interactive:"\u0645interactive",personalization:"\u0630\u0627\u062a\u06cc \u0646\u0648\u0639\u06cc\u062a",adaptive:"\u0645\u0637\u0627\u0628\u0642\u062a \u067e\u0630\u06cc\u0631",customization:"\u0627\u067e\u0646\u06cc \u0645\u0631\u0636\u06cc \u06a9\u06d2 \u0645\u0637\u0627\u0628\u0642",preference:"\u062a\u0631\u062c\u06cc\u062d",user:"\u0635\u0627\u0631\u0641",profile:"\u067e\u0631\u0648\u0641\u0627\u0626\u0644",language:"\u0632\u0628\u0627\u0646",english:"\u0627\u0646\u06af\u0631\u06cc\u0632\u06cc",urdu:"\u0627\u0631\u062f\u0648",begin:"\u0634\u0631\u0648\u0639 \u06a9\u0631\u06cc\u06ba",start:"\u0634\u0631\u0648\u0639",continue:"\u062c\u0627\u0631\u06cc \u0631\u06a9\u06be\u06cc\u06ba",next:"\u0627\u06af\u0644\u0627",previous:"\u067e\u0686\u06be\u0644\u0627",end:"\u062e\u062a\u0645",finish:"\u062e\u062a\u0645 \u06a9\u0631\u06cc\u06ba",complete:"\u0645\u06a9\u0645\u0644",done:"\u06c1\u0648 \u06af\u06cc\u0627",success:"\u06a9\u0627\u0645\u06cc\u0627\u0628\u06cc",achieve:"\u062d\u0627\u0635\u0644 \u06a9\u0631\u06cc\u06ba",goal:"\u06c1\u062f\u0641",objective:"\u0645\u0642\u0635\u062f",target:"\u06c1\u062f\u0641",aim:"\u06c1\u062f\u0641",purpose:"\u0645\u0642\u0635\u062f",reason:"\u0648\u062c\u06c1",why:"\u06a9\u06cc\u0648\u06ba",how:"\u06a9\u06cc\u0633\u06d2",what:"\u06a9\u06cc\u0627",where:"\u06a9\u06c1\u0627\u06ba",when:"\u06a9\u0628",who:"\u06a9\u0648\u0646",which:"\u06a9\u0648\u0646 \u0633\u0627",can:"\u06a9\u0631 \u0633\u06a9\u062a\u0627 \u06c1\u06d2",will:"\u06a9\u0631\u06d2 \u06af\u0627",should:"\u0686\u0627\u06c1\u06cc\u06d2",must:"\u0636\u0631\u0648\u0631",may:"\u0634\u0627\u06cc\u062f",might:"\u0634\u0627\u06cc\u062f",could:"\u06a9\u0631 \u0633\u06a9\u062a\u0627 \u062a\u06be\u0627",would:"\u06a9\u0631\u062a\u0627",if:"\u0627\u06af\u0631",then:"\u067e\u06be\u0631",else:"\u0648\u0631\u0646\u06c1",for:"\u06a9\u06d2 \u0644\u06cc\u06d2",to:"\u06a9\u0648",of:"\u06a9\u0627",and:"\u0627\u0648\u0631",or:"\u06cc\u0627",not:"\u0646\u06c1\u06cc\u06ba",is:"\u06c1\u06d2",are:"\u06c1\u06cc\u06ba",was:"\u062a\u06be\u0627",were:"\u062a\u06be\u06d2",be:"\u06c1\u0648\u0646\u0627",been:"\u06c1\u0648\u0627",being:"\u06c1\u0648\u062a\u06d2 \u06c1\u0648\u0626\u06d2",have:"\u0631\u06a9\u06be\u062a\u0627 \u06c1\u06d2",has:"\u0631\u06a9\u06be\u062a\u0627 \u06c1\u06d2",had:"\u0631\u06a9\u06be\u0627",do:"\u06a9\u0631\u0646\u0627",does:"\u06a9\u0631\u062a\u0627 \u06c1\u06d2",did:"\u06a9\u06cc\u0627",say:"\u06a9\u06c1\u0646\u0627",says:"\u06a9\u06c1\u062a\u0627 \u06c1\u06d2",said:"\u06a9\u06c1\u0627",get:"\u062d\u0627\u0635\u0644 \u06a9\u0631\u0646\u0627",got:"\u062d\u0627\u0635\u0644 \u06a9\u06cc\u0627",go:"\u062c\u0627\u0646\u0627",goes:"\u062c\u0627\u062a\u0627 \u06c1\u06d2",went:"\u06af\u06cc\u0627",make:"\u0628\u0646\u0627\u0646\u0627",makes:"\u0628\u0646\u0627 \u062f\u06cc\u062a\u0627 \u06c1\u06d2",made:"\u0628\u0646\u0627\u06cc\u0627",take:"\u0644\u06cc\u0646\u0627",takes:"\u0644\u06cc\u062a\u0627 \u06c1\u06d2",took:"\u0644\u06cc\u0627",see:"\u062f\u06cc\u06a9\u06be\u0646\u0627",sees:"\u062f\u06cc\u06a9\u06be\u062a\u0627 \u06c1\u06d2",saw:"\u062f\u06cc\u06a9\u06be\u0627",come:"\u0622\u0646\u0627",comes:"\u0622\u062a\u0627 \u06c1\u06d2",came:"\u0622\u06cc\u0627",think:"\u0633\u0648\u0686\u0646\u0627",thinks:"\u0633\u0648\u0686\u062a\u0627 \u06c1\u06d2",thought:"\u0633\u0648\u0686\u0627",look:"\u062f\u06cc\u06a9\u06be\u0646\u0627",looks:"\u062f\u06cc\u06a9\u06be\u062a\u0627 \uff48\u06d2",looked:"\u062f\u06cc\u06a9\u06be\u0627",want:"\u0686\u0627\u06c1\u0646\u0627",wants:"\u0686\u0627\u06c1\u062a\u0627 \u06c1\u06d2",wanted:"\u0686\u0627\u06c1\u062a\u0627 \u062a\u06be\u0627",give:"\u062f\u06cc\u0646\u0627",gives:"\u062f\u06cc\u062a\u0627 \u06c1\u06d2",gave:"\u062f\u06cc\u0627",use:"\u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u0646\u0627",uses:"\u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",used:"\u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u06cc\u0627",find:"\u0688\u06be\u0648\u0646\u0688\u0646\u0627",finds:"\u0688\u06be\u0648\u0646\u0688\u062a\u0627 \u06c1\u06d2",found:"\u0688\u06be\u0648\u0646\u0688 \u0644\u06cc\u0627",tell:"\u0628\u062a\u0627\u0646\u0627",tells:"\u0628\u062a\u0627\u062a\u0627 \u06c1\u06d2",told:"\u0628\u062a\u0627\u06cc\u0627",ask:"\u067e\u0648\u0686\u06be\u0646\u0627",asks:"\u067e\u0648\u0686\u06be\u062a\u0627 \u06c1\u06d2",asked:"\u067e\u0648\u0686\u06be\u0627",work:"\u06a9\u0627\u0645",works:"\u06a9\u0627\u0645 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",worked:"\u06a9\u0627\u0645 \u06a9\u06cc\u0627",seem:"\u0644\u06af\u062a\u0627 \u06c1\u06d2",seems:"\u0644\u06af\u062a\u0627 \u06c1\u06d2",seemed:"\u0644\u06af\u0627",feel:"\u0645\u062d\u0633\u0648\u0633 \u06a9\u0631\u0646\u0627",feels:"\u0645\u062d\u0633\u0648\u0633 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",felt:"\u0645\u062d\u0633\u0648\u0633 \u06a9\u06cc\u0627",try:"\u06a9\u0648\u0634\u0634 \u06a9\u0631\u0646\u0627",tries:"\u06a9\u0648\u0634\u0634 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",tried:"\u06a9\u0648\u0634\u0634 \u06a9\u06cc",leave:"\u0686\u06be\u0648\u0691\u0646\u0627",leaves:"\u0686\u06be\u0648\u0691 \u062f\u06cc\u062a\u0627 \u06c1\u06d2",left:"\u0686\u06be\u0648\u0691 \u062f\u06cc\u0627",call:"\u06a9\u0627\u0644 \u06a9\u0631\u0646\u0627",calls:"\u06a9\u0627\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",called:"\u06a9\u0627\u0644 \u06a9\u06cc",need:"\u0636\u0631\u0648\u0631\u062a \u06c1\u06d2",needs:"\u0636\u0631\u0648\u0631\u062a \u06c1\u06d2",needed:"\u0636\u0631\u0648\u0631\u062a \u062a\u06be\u06cc",become:"\u0628\u0646\u0646\u0627",becomes:"\u0628\u0646\u062a\u0627 \u06c1\u06d2",became:"\u0628\u0646 \u06af\u06cc\u0627",happen:"\u06c1\u0648\u0646\u0627",happens:"\u06c1\u0648\u062a\u0627 \u06c1\u06d2",happened:"\u06c1\u0648\u0627",show:"\u062f\u06a9\u06be\u0627\u0646\u0627",shows:"\u062f\u06a9\u06be\u0627\u062a\u0627 \u06c1\u06d2",showed:"\u062f\u06a9\u06be\u0627\u06cc\u0627",mean:"\u0645\u0637\u0644\u0628",means:"\u0645\u0637\u0644\u0628 \u06c1\u06d2",meant:"\u0645\u0637\u0644\u0628 \u062a\u06be\u0627",put:"\u0688\u0627\u0644\u0646\u0627",set:"\u0633\u06cc\u0679 \u06a9\u0631\u0646\u0627",sets:"\u0633\u06cc\u0679 \u06a9\u0631\u062a\u0627 \u06c1\u06d2",set:"\u0633\u06cc\u0679",help:"\u0645\u062f\u062f",helps:"\u0645\u062f\u062f \u06a9\u0631\u062a\u0627 \u06c1\u06d2",helped:"\u0645\u062f\u062f \u06a9\u06cc",play:"\u06a9\u06be\u06cc\u0644\u0646\u0627",plays:"\u06a9\u06be\u06cc\u0644\u062a\u0627 \u06c1\u06d2",played:"\u06a9\u06be\u06cc\u0644\u0627",run:"\u0686\u0644\u0646\u0627",runs:"\u0686\u0644\u062a\u0627 \u06c1\u06d2",ran:"\u0686\u0644\u0627",move:"\u0645\u0646\u062a\u0642\u0644 \u06c1\u0648\u0646\u0627",moves:"\u0645\u0646\u062a\u0642\u0644 \u06c1\u0648\u062a\u0627 \u06c1\u06d2",moved:"\u0645\u0646\u062a\u0642\u0644 \u06c1\u0648 \u06af\u06cc\u0627",live:"\u0631\u06c1\u0646\u0627",lives:"\u0631\u06c1\u062a\u0627 \u06c1\u06d2",lived:"\u0631\u06c1\u0627",believe:"\u06cc\u0642\u06cc\u0646 \u06a9\u0631\u0646\u0627",believes:"\u06cc\u0642\u06cc\u0646 \u0631\u06a9\u06be\u062a\u0627 \u06c1\u06d2",believed:"\u06cc\u0642\u06cc\u0646 \u06a9\u06cc\u0627",hold:"\u067e\u06a9\u0691\u0646\u0627",holds:"\u067e\u06a9\u0691\u062a\u0627 \u06c1\u06d2",held:"\u067e\u06a9\u0691\u0627",bring:"\u0644\u0627\u0646\u0627",brings:"\u0644\u0627\u062a\u0627 \u06c1\u06d2",brought:"\u0644\u0627\u06cc\u0627",must:"\u0636\u0631\u0648\u0631",should:"\u0686\u0627\u06c1\u06cc\u06d2",would:"\u06a9\u0631\u06d2 \u06af\u0627",could:"\u06a9\u0631 \u0633\u06a9\u062a\u0627 \u06c1\u06d2",can:"\u06a9\u0631 \u0633\u06a9\u062a\u0627 \u06c1\u06d2",will:"\u06a9\u0631\u06d2 \u06af\u0627",shall:"\u06a9\u0631\u06d2 \u06af\u0627",yes:"\u06c1\u0627\u06ba",no:"\u0646\u06c1\u06cc\u06ba",not:"\u0646\u06c1\u06cc\u06ba",ok:"\u0679\u06be\u06cc\u06a9 \u06c1\u06d2",okay:"\u0679\u06be\u06cc\u06a9 \u06c1\u06d2",good:"\u0627\u0686\u06be\u0627",great:"\u0639\u0638\u06cc\u0645",excellent:"\u0634\u0627\u0646\u062f\u0627\u0631",amazing:"\u0627\u0686\u06be\u0627",wonderful:"\u0627\u0686\u06be\u0627",fantastic:"\u0634\u0627\u0646\u062f\u0627\u0631",perfect:"\u06a9\u0627\u0645\u0644",right:"\u0635\u062d\u06cc\u062d",correct:"\u0635\u062d\u06cc\u062d",wrong:"\u063a\u0644\u0637",bad:"\u0628\u0631\u0627",terrible:"\u0628\u064f\u0631\u0627",awful:"\u0628\u064f\u0631\u0627",poor:"\u063a\u0631\u06cc\u0628",rich:"\u0627\u0645\u06cc\u0631",big:"\u0628\u0691\u0627",large:"\u0628\u0691\u0627",huge:"\u0628\u06c1\u062a \u0628\u0691\u0627",small:"\u0686\u06be\u0648\u0679\u0627",little:"\u0686\u06be\u0648\u0679\u0627",tiny:"\u0646\u0646\u06be\u0627",short:"\u0686\u06be\u0648\u0679\u0627",long:"\u0644\u0645\u0628\u0627",tall:"\u0644\u0645\u0628\u0627",high:"\u0686\u0646\u0627",low:"\u06a9\u0645",deep:"\u06af\u06c1\u0631\u0627",shallow:"\u0686\u06be\u0631\u0627",wide:"\u0686\u0648\u0691\u0627",narrow:"\u062a\u0646\u06af",thick:"\u0645\u0648\u0679\u0627",thin:"\u067e\u062a\u0644\u06cc",heavy:"\u0628\u06be\u0627\u0631\u06cc",light:"\u06c1\u0644\u06a9\u0627",fast:"\u062a\u06cc\u0632",quick:"\u062a\u06cc\u0632",slow:"\u0633\u0633\u062a",late:"\u062f\u06cc\u0631",early:"\u062c\u0644\u062f",new:"\u0646\u06cc\u0627",old:"\u067e\u0631\u0627\u0646\u0627",young:"\u0646\u0648\u062c\u0648\u0627\u0646",ancient:"\u0642\u062f\u06cc\u0645",modern:"\u062c\u062f\u06cc\u062f",future:"\u0645\u0633\u062a\u0642\u0628\u0644",past:"\u0645\u0627\u0636\u06cc",present:"\u062d\u0627\u0644",now:"\u0627\u0628",then:"\u067e\u06be\u0631",today:"\u0622\u062c",tomorrow:"\u06a9\u0644",yesterday:"\u06a9\u0644",morning:"\u0635\u0628\u062d",afternoon:"\u062f\u0648\u067e\u06c1\u0631",evening:"\u0634\u0627\u0645",night:"\u0631\u0627\u062a",day:"\u062f\u0646",week:"\u06c1\u0641\u062a\u06c1",month:"\u0645\u06c1\u06cc\u0646\u06c1",year:"\u0633\u0627\u0644",time:"\u0648\u0642\u062a",moment:"\u0644\u0645\u062d\u06c1",hour:"\u06af\u06be\u0646\u0679\u06c1",minute:"\u0645\u0646\u0679",second:"\u0633\u06cc\u06a9\u0646\u0688",first:"\u067e\u06c1\u0644\u0627",second:"\u062f\u0648\u0633\u0631\u0627",third:"\u062a\u06cc\u0633\u0631\u0627",last:"\u0622\u062e\u0631\u06cc",next:"\u0627\u06af\u0644\u0627",previous:"\u067e\u0686\u06be\u0644\u0627",one:"\u0627\u06cc\u06a9",two:"\u062f\u0648",three:"\u062a\u06cc\u0646",four:"\u0686\u0627\u0631",five:"\u067e\u0627\u0646\u0686",six:"\u0686\u06be",seven:"\u0633\u0627\u062a",eight:"\u0622\u0679\u06be",nine:"\u0646\u0648",ten:"\u062f\u0633",eleven:"\u06af\u06cc\u0627\u0631\u06c1",twelve:"\u0628\u0627\u0631\u06c1",thirteen:"\u062a\u06cc\u0631\u06c1",fourteen:"\u0686\u0648\u062f\u06c1",fifteen:"\u067e\u0646\u062f\u0631\u06c1",sixteen:"\u0633\u0648\u0644\u06c1",seventeen:"\u0633\u062a\u0631\u06c1",eighteen:"\u0627\u0679\u06be\u0627\u0631\u06c1",nineteen:"\u0627\u0646\u06cc\u0633",twenty:"\u0628\u06cc\u0633",thirty:"\u062a\u06cc\u0633",forty:"\u0686\u0627\u0644\u06cc\u0633",fifty:"\u067e\u0686\u0627\u0633",sixty:"\u0633\u0679\u06be",seventy:"\u0633\u062a\u0631",eighty:"\u0627\u0633\u06cc",ninety:"\u0646\u0648\u06d2",hundred:"\u0633\u0648",thousand:"\u06c1\u0632\u0627\u0631",million:"\u0645\u0644\u06cc\u0646",billion:"\u0628\u0644\u06cc\u0646",more:"\u0645\u0632\u06cc\u062f",less:"\u06a9\u0645",many:"\u0628\u06c1\u062a",much:"\u0628\u06c1\u062a",few:"\u06a9\u0645",several:"\u06a9\u0626\u06cc",all:"\u0633\u0628",every:"\u06c1\u0631",each:"\u06c1\u0631 \u0627\u06cc\u06a9",some:"\u06a9\u0686\u06be",any:"\u06a9\u0648\u0626\u06cc",none:"\u06a9\u0648\u0626\u06cc \u0646\u06c1\u06cc\u06ba",nothing:"\u06a9\u0686\u06be \u0646\u06c1\u06cc\u06ba",everything:"\u0633\u0628 \u06a9\u0686\u06be",something:"\u06a9\u0686\u06be",anything:"\u06a9\u0648\u0626\u06cc \u0686\u06cc\u0632",here:"\u06cc\u06c1\u0627\u06ba",there:"\u0648\u06c1\u0627\u06ba",where:"\u06a9\u06c1\u0627\u06ba",this:"\u06cc\u06c1",that:"\u0648\u06c1",these:"\u06cc\u06c1",those:"\u0648\u06c1",who:"\u06a9\u0648\u0646",what:"\u06a9\u06cc\u0627",which:"\u06a9\u0648\u0646 \u0633\u0627",whose:"\u062c\u0633 \u06a9\u0627",whom:"\u062c\u0633\u06d2",when:"\u06a9\u0628",where:"\u06a9\u06c1\u0627\u06ba",why:"\u06a9\u06cc\u0648\u06ba",how:"\u06a9\u06cc\u0633\u06d2",i:"\u0645\u06cc\u06ba",you:"\u0622\u067e",he:"\u0648\u06c1",she:"\u0648\u06c1",it:"\u06cc\u06c1",we:"\u06c1\u0645",they:"\u0648\u06c1",me:"\u0645\u062c\u06be\u06d2",him:"\u0627\u0633\u06d2",her:"\u0627\u0633\u06d2",us:"\u06c1\u0645\u06cc\u06ba",them:"\u0627\u0646\u06c1\u06cc\u06ba",my:"\u0645\u06cc\u0631\u0627",your:"\u0622\u067e \u06a9\u0627",his:"\u0627\u0633 \u06a9\u0627",her:"\u0627\u0633 \u06a9\u0627",its:"\u0627\u0633 \u06a9\u0627",our:"\u06c1\u0645\u0627\u0631\u0627",their:"\u0627\u0646 \u06a9\u0627",mine:"\u0645\u06cc\u0631\u0627",yours:"\u0622\u067e \u06a9\u0627",hers:"\u0627\u0633 \u06a9\u0627",ours:"\u06c1\u0645\u0627\u0631\u0627",theirs:"\u0627\u0646 \u06a9\u0627",myself:"\u062e\u0648\u062f",yourself:"\u0622\u067e \u062e\u0648\u062f",himself:"\u062e\u0648\u062f",herself:"\u062e\u0648\u062f",itself:"\u062e\u0648\u062f",ourselves:"\u062e\u0648\u062f",yourselves:"\u0622\u067e \u062e\u0648\u062f",themselves:"\u062e\u0648\u062f"};(0,t.useEffect)(()=>{n&&r?(d(!0),setTimeout(()=>{o((e=>{if(!e||"string"!=typeof e)return e;let n=e;const i=Object.keys(m).sort((e,n)=>n.length-e.length);for(const t of i){const e=new RegExp(`\\b${t}\\b`,"gi");n=n.replace(e,e=>{const n=e.toLowerCase(),i=m[n];return i?e===e.toUpperCase()?i.toUpperCase():e===e.charAt(0).toUpperCase()+e.slice(1).toLowerCase()?i.charAt(0).toUpperCase()+i.slice(1).toLowerCase():i:e})}return n})(e)),d(!1)},100)):o(e)},[e,r,n]);return(0,a.jsxs)("div",{className:"translate-to-urdu",children:[(0,a.jsx)("div",{className:"translation-controls",children:(0,a.jsx)("button",{onClick:()=>{n&&l(!r)},disabled:!n,className:"translate-toggle "+(r?"active":""),children:c?"\u062a\u0631\u062c\u0645\u06c1 \u06c1\u0648 \u0631\u06c1\u0627 \u06c1\u06d2...":r?"\u0627\u0646\u06af\u0631\u06cc\u0632\u06cc \u0645\u06cc\u06ba \u062f\u06cc\u06a9\u06be\u06cc\u06ba":"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u062a\u0631\u062c\u0645\u06c1 \u06a9\u0631\u06cc\u06ba"})}),(0,a.jsx)("div",{className:"translated-content",children:c?(0,a.jsx)("div",{className:"loading",children:"...\u0644\u0648\u0688 \u06c1\u0648 \u0631\u06c1\u0627 \u06c1\u06d2"}):s})]})},r=e=>(0,a.jsx)(s.A,{children:()=>(0,a.jsx)(o,{...e})})}}]);