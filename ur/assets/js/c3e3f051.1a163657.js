"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[2177],{6413:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>_,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"weekly-breakdown/week11/index","title":"Week 11 - AI Planning and Decision Making","description":"Learning Objectives","source":"@site/docs/weekly-breakdown/week11/index.mdx","sourceDirName":"weekly-breakdown/week11","slug":"/weekly-breakdown/week11/","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week11/","draft":false,"unlisted":false,"editUrl":"https://github.com/fatima317/physical-ai-book/tree/main/docs/weekly-breakdown/week11/index.mdx","tags":[],"version":"current","sidebarPosition":11,"frontMatter":{"sidebar_position":11,"title":"Week 11 - AI Planning and Decision Making"},"sidebar":"tutorialSidebar","previous":{"title":"Week 10 - Perception and Sensor Fusion","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week10/"},"next":{"title":"Week 12: Integration and Deployment","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week12/"}}');var i=t(4848),o=t(8453);const r={sidebar_position:11,title:"Week 11 - AI Planning and Decision Making"},s="Week 11 - AI Planning and Decision Making",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Planning in Robotics",id:"planning-in-robotics",level:2},{value:"Code Snippets",id:"code-snippets",level:2},{value:"Path Planning Algorithms",id:"path-planning-algorithms",level:3},{value:"Finite State Machine Implementation",id:"finite-state-machine-implementation",level:3},{value:"Behavior Trees Implementation",id:"behavior-trees-implementation",level:3},{value:"URDF Examples",id:"urdf-examples",level:2},{value:"Robot with Planning Capabilities",id:"robot-with-planning-capabilities",level:3},{value:"Planning Algorithm Comparison",id:"planning-algorithm-comparison",level:2},{value:"Behavior Tree Elements",id:"behavior-tree-elements",level:2},{value:"Key Terms",id:"key-terms",level:2},{value:"Learning Checkpoints",id:"learning-checkpoints",level:2},{value:"Quiz Questions",id:"quiz-questions",level:3},{value:"Practical Exercise",id:"practical-exercise",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Personalization",id:"personalization",level:2},{value:"Translation",id:"translation",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"week-11---ai-planning-and-decision-making",children:"Week 11 - AI Planning and Decision Making"})}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this week, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Implement classical planning algorithms for robotics"}),"\n",(0,i.jsx)(e.li,{children:"Apply search algorithms (A*, Dijkstra, RRT) for path planning"}),"\n",(0,i.jsx)(e.li,{children:"Design decision-making systems using finite state machines"}),"\n",(0,i.jsx)(e.li,{children:"Implement behavior trees for complex robot behaviors"}),"\n",(0,i.jsx)(e.li,{children:"Apply reinforcement learning for planning and control"}),"\n",(0,i.jsx)(e.li,{children:"Integrate planning with perception and control systems"}),"\n",(0,i.jsx)(e.li,{children:"Evaluate planning algorithms for optimality and efficiency"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"planning-in-robotics",children:"Planning in Robotics"}),"\n",(0,i.jsx)(e.p,{children:"AI planning is crucial for enabling robots to make intelligent decisions and execute complex tasks. Planning algorithms help robots determine sequences of actions to achieve goals while considering constraints and optimizing for various criteria. Key planning types include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Motion Planning"}),": Finding collision-free paths through configuration space"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Task Planning"}),": Sequencing high-level tasks to achieve goals"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Temporal Planning"}),": Considering timing and duration of actions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-Agent Planning"}),": Coordinating multiple agents/robots"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Contingency Planning"}),": Handling uncertainties and exceptions"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"code-snippets",children:"Code Snippets"}),"\n",(0,i.jsx)(e.h3,{id:"path-planning-algorithms",children:"Path Planning Algorithms"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport heapq\nfrom typing import List, Tuple, Optional, Dict, Set\nimport matplotlib.pyplot as plt\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n@dataclass\nclass Node:\n    """Node for path planning algorithms"""\n    x: float\n    y: float\n    cost: float = 0.0\n    parent: Optional[\'Node\'] = None\n\n    def __lt__(self, other):\n        return self.cost < other.cost\n\n    def __eq__(self, other):\n        return self.x == other.x and self.y == other.y\n\nclass GridMap:\n    """Grid-based representation of the environment"""\n    def __init__(self, width: int, height: int, resolution: float = 1.0):\n        self.width = width\n        self.height = height\n        self.resolution = resolution\n        self.grid = np.zeros((height, width), dtype=bool)  # False = free, True = occupied\n\n    def is_free(self, x: float, y: float) -> bool:\n        """Check if a position is free (not occupied)"""\n        if x < 0 or x >= self.width or y < 0 or y >= self.height:\n            return False\n        return not self.grid[int(y)][int(x)]\n\n    def set_obstacle(self, x: int, y: int):\n        """Set a cell as occupied"""\n        if 0 <= x < self.width and 0 <= y < self.height:\n            self.grid[y][x] = True\n\n    def get_neighbors(self, node: Node) -> List[Node]:\n        """Get valid neighboring nodes (8-connected)"""\n        neighbors = []\n\n        # 8-connected neighborhood (including diagonals)\n        for dx in [-1, 0, 1]:\n            for dy in [-1, 0, 1]:\n                if dx == 0 and dy == 0:\n                    continue  # Skip current node\n\n                new_x = node.x + dx\n                new_y = node.y + dy\n\n                if self.is_free(new_x, new_y):\n                    # Calculate movement cost (diagonal vs straight)\n                    move_cost = np.sqrt(2) if dx != 0 and dy != 0 else 1.0\n                    neighbors.append(Node(new_x, new_y, node.cost + move_cost, node))\n\n        return neighbors\n\nclass AStarPlanner:\n    """A* path planning algorithm implementation"""\n    def __init__(self, grid_map: GridMap):\n        self.grid_map = grid_map\n\n    def heuristic(self, node: Node, goal: Node) -> float:\n        """Heuristic function for A* (Euclidean distance)"""\n        return np.sqrt((node.x - goal.x)**2 + (node.y - goal.y)**2)\n\n    def plan_path(self, start: Node, goal: Node) -> Optional[List[Node]]:\n        """\n        Plan path from start to goal using A* algorithm\n\n        Args:\n            start: Start node\n            goal: Goal node\n\n        Returns:\n            List of nodes forming the path, or None if no path exists\n        """\n        # Priority queue: (f_score, node)\n        open_set = [(0.0, start)]\n\n        # Keep track of visited nodes and their g_scores\n        g_scores = {start: start.cost}\n        closed_set = set()\n\n        while open_set:\n            current_f, current = heapq.heappop(open_set)\n\n            # Check if we reached the goal\n            if current.x == goal.x and current.y == goal.y:\n                return self.reconstruct_path(current)\n\n            # Mark as visited\n            closed_set.add((current.x, current.y))\n\n            # Explore neighbors\n            for neighbor in self.grid_map.get_neighbors(current):\n                if (neighbor.x, neighbor.y) in closed_set:\n                    continue\n\n                # Calculate tentative g_score\n                tentative_g = g_scores[current] + self.get_move_cost(current, neighbor)\n\n                # If this path to neighbor is better than previous one\n                if neighbor not in g_scores or tentative_g < g_scores[neighbor]:\n                    g_scores[neighbor] = tentative_g\n                    f_score = tentative_g + self.heuristic(neighbor, goal)\n\n                    # Add to open set\n                    heapq.heappush(open_set, (f_score, neighbor))\n\n        # No path found\n        return None\n\n    def get_move_cost(self, node1: Node, node2: Node) -> float:\n        """Calculate movement cost between two adjacent nodes"""\n        return np.sqrt((node1.x - node2.x)**2 + (node1.y - node2.y)**2)\n\n    def reconstruct_path(self, goal_node: Node) -> List[Node]:\n        """Reconstruct path from goal to start by following parent pointers"""\n        path = []\n        current = goal_node\n\n        while current is not None:\n            path.append(current)\n            current = current.parent\n\n        # Reverse to get path from start to goal\n        return path[::-1]\n\nclass RRTPlanner:\n    """Rapidly-Exploring Random Tree (RRT) path planning algorithm"""\n    def __init__(self, grid_map: GridMap, step_size: float = 1.0, max_iterations: int = 10000):\n        self.grid_map = grid_map\n        self.step_size = step_size\n        self.max_iterations = max_iterations\n\n    def plan_path(self, start: Node, goal: Node, goal_bias: float = 0.1) -> Optional[List[Node]]:\n        """\n        Plan path using RRT algorithm\n\n        Args:\n            start: Start configuration\n            goal: Goal configuration\n            goal_bias: Probability of sampling goal instead of random point\n\n        Returns:\n            List of nodes forming the path, or None if no path found\n        """\n        # Initialize tree with start node\n        tree = [start]\n        nodes_dict = {(start.x, start.y): start}\n\n        for iteration in range(self.max_iterations):\n            # Sample random point (with bias toward goal)\n            if np.random.random() < goal_bias:\n                rand_x, rand_y = goal.x, goal.y\n            else:\n                rand_x = np.random.uniform(0, self.grid_map.width)\n                rand_y = np.random.uniform(0, self.grid_map.height)\n\n            rand_node = Node(rand_x, rand_y)\n\n            # Find nearest node in tree\n            nearest_node = self.find_nearest(tree, rand_node)\n\n            # Extend tree toward random point\n            new_node = self.extend_toward(nearest_node, rand_node)\n\n            if new_node is not None:\n                tree.append(new_node)\n                nodes_dict[(new_node.x, new_node.y)] = new_node\n\n                # Check if we\'re close to goal\n                if self.distance(new_node, goal) < self.step_size:\n                    # Connect to goal and return path\n                    goal.parent = new_node\n                    return self.reconstruct_path_to_start(goal, nodes_dict)\n\n        # Path not found\n        return None\n\n    def find_nearest(self, tree: List[Node], target: Node) -> Node:\n        """Find nearest node in tree to target"""\n        nearest = tree[0]\n        min_dist = self.distance(nearest, target)\n\n        for node in tree[1:]:\n            dist = self.distance(node, target)\n            if dist < min_dist:\n                min_dist = dist\n                nearest = node\n\n        return nearest\n\n    def extend_toward(self, from_node: Node, to_node: Node) -> Optional[Node]:\n        """Extend tree from from_node toward to_node"""\n        direction = np.array([to_node.x - from_node.x, to_node.y - from_node.y])\n        dist = np.linalg.norm(direction)\n\n        if dist < self.step_size:\n            # If target is close enough, just connect directly\n            if self.grid_map.is_free(to_node.x, to_node.y):\n                to_node.cost = from_node.cost + dist\n                to_node.parent = from_node\n                return to_node\n        else:\n            # Move step_size toward target\n            direction_norm = direction / dist\n            new_x = from_node.x + direction_norm[0] * self.step_size\n            new_y = from_node.y + direction_norm[1] * self.step_size\n\n            if self.grid_map.is_free(new_x, new_y):\n                new_node = Node(new_x, new_y)\n                new_node.cost = from_node.cost + self.step_size\n                new_node.parent = from_node\n                return new_node\n\n        return None\n\n    def distance(self, node1: Node, node2: Node) -> float:\n        """Calculate Euclidean distance between nodes"""\n        return np.sqrt((node1.x - node2.x)**2 + (node1.y - node2.y)**2)\n\n    def reconstruct_path_to_start(self, goal_node: Node, nodes_dict: Dict) -> List[Node]:\n        """Reconstruct path from goal to start"""\n        path = []\n        current = goal_node\n\n        while current is not None:\n            path.append(current)\n            current = current.parent\n\n        # Reverse to get path from start to goal\n        return path[::-1]\n\n# Example usage\ndef example_path_planning():\n    # Create a grid map with some obstacles\n    grid_map = GridMap(50, 50)\n\n    # Add some obstacles\n    for i in range(10, 20):\n        grid_map.set_obstacle(i, 25)\n\n    for i in range(30, 40):\n        grid_map.set_obstacle(35, i)\n\n    # Define start and goal positions\n    start = Node(5.0, 5.0)\n    goal = Node(45.0, 45.0)\n\n    # Test A* planning\n    astar_planner = AStarPlanner(grid_map)\n    astar_path = astar_planner.plan_path(start, goal)\n\n    if astar_path:\n        print(f"A* found path with {len(astar_path)} nodes")\n    else:\n        print("A* could not find a path")\n\n    # Test RRT planning\n    rrt_planner = RRTPlanner(grid_map, step_size=2.0)\n    rrt_path = rrt_planner.plan_path(start, goal)\n\n    if rrt_path:\n        print(f"RRT found path with {len(rrt_path)} nodes")\n    else:\n        print("RRT could not find a path")\n\n    # Visualize results (if matplotlib is available)\n    try:\n        plt.figure(figsize=(12, 5))\n\n        # Plot grid map\n        plt.subplot(1, 2, 1)\n        plt.imshow(grid_map.grid, cmap=\'binary\', origin=\'lower\')\n        plt.title(\'Grid Map with Obstacles\')\n\n        # Plot A* path\n        if astar_path:\n            path_x = [node.x for node in astar_path]\n            path_y = [node.y for node in astar_path]\n            plt.plot(path_x, path_y, \'r-\', linewidth=2, label=\'A* Path\')\n            plt.scatter(start.x, start.y, c=\'green\', s=100, label=\'Start\')\n            plt.scatter(goal.x, goal.y, c=\'red\', s=100, label=\'Goal\')\n\n        plt.legend()\n        plt.grid(True)\n\n        # Plot RRT tree\n        plt.subplot(1, 2, 2)\n        plt.imshow(grid_map.grid, cmap=\'binary\', origin=\'lower\')\n        plt.title(\'RRT Tree\')\n\n        # Plot RRT path\n        if rrt_path:\n            path_x = [node.x for node in rrt_path]\n            path_y = [node.y for node in rrt_path]\n            plt.plot(path_x, path_y, \'r-\', linewidth=2, label=\'RRT Path\')\n            plt.scatter(start.x, start.y, c=\'green\', s=100, label=\'Start\')\n            plt.scatter(goal.x, goal.y, c=\'red\', s=100, label=\'Goal\')\n\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n    except ImportError:\n        print("Matplotlib not available for visualization")\n'})}),"\n",(0,i.jsx)(e.h3,{id:"finite-state-machine-implementation",children:"Finite State Machine Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'from enum import Enum\nfrom abc import ABC, abstractmethod\nimport time\nfrom typing import Any, Dict, Optional\n\nclass RobotState(Enum):\n    """Enumeration of possible robot states"""\n    IDLE = "idle"\n    NAVIGATING = "navigating"\n    MANIPULATING = "manipulating"\n    PERCEIVING = "perceiving"\n    CHARGING = "charging"\n    EMERGENCY_STOP = "emergency_stop"\n\nclass State(ABC):\n    """Abstract base class for robot states"""\n\n    def __init__(self, name: str):\n        self.name = name\n        self.start_time = None\n\n    def enter(self, robot):\n        """Called when entering the state"""\n        self.start_time = time.time()\n        print(f"Entering state: {self.name}")\n\n    def exit(self, robot):\n        """Called when exiting the state"""\n        print(f"Exiting state: {self.name}")\n\n    @abstractmethod\n    def execute(self, robot, sensors_data: Dict[str, Any]) -> RobotState:\n        """\n        Execute state behavior and return next state\n\n        Args:\n            robot: Robot instance\n            sensors_data: Dictionary of sensor readings\n\n        Returns:\n            Next state to transition to\n        """\n        pass\n\n    def get_duration(self) -> float:\n        """Get time spent in current state"""\n        if self.start_time is not None:\n            return time.time() - self.start_time\n        return 0.0\n\nclass IdleState(State):\n    """Robot is waiting for commands"""\n\n    def __init__(self):\n        super().__init__(RobotState.IDLE)\n        self.inactivity_threshold = 30.0  # seconds\n\n    def execute(self, robot, sensors_data: Dict[str, Any]) -> RobotState:\n        # Check if there\'s a navigation goal\n        if robot.has_navigation_goal():\n            return RobotState.NAVIGATING\n\n        # Check if there\'s a manipulation task\n        if robot.has_manipulation_task():\n            return RobotState.MANIPULATING\n\n        # Check if there\'s a charging request\n        if robot.needs_charging():\n            return RobotState.CHARGING\n\n        # Check for emergency stop\n        if sensors_data.get(\'emergency_stop\', False):\n            return RobotState.EMERGENCY_STOP\n\n        # Check for inactivity timeout\n        if self.get_duration() > self.inactivity_threshold:\n            # Robot goes into low-power mode or performs periodic checks\n            robot.perform_periodic_tasks()\n\n        return RobotState.IDLE\n\nclass NavigatingState(State):\n    """Robot is moving to a destination"""\n\n    def __init__(self):\n        super().__init__(RobotState.NAVIGATING)\n        self.path_executor = None\n        self.replan_threshold = 0.5  # meters\n        self.max_replan_attempts = 5\n\n    def enter(self, robot):\n        super().enter(robot)\n        # Plan path to goal\n        self.path_executor = robot.get_path_executor()\n        self.path_executor.plan_to_goal(robot.get_current_goal())\n        self.replan_attempts = 0\n\n    def execute(self, robot, sensors_data: Dict[str, Any]) -> RobotState:\n        # Check for obstacles in path\n        obstacles = sensors_data.get(\'obstacles\', [])\n\n        if self.path_executor.has_obstacle_ahead(obstacles, self.replan_threshold):\n            # Replan path\n            self.replan_attempts += 1\n            if self.replan_attempts < self.max_replan_attempts:\n                self.path_executor.replan()\n            else:\n                # Too many replanning attempts - go to idle\n                robot.cancel_navigation()\n                return RobotState.IDLE\n\n        # Execute path following\n        self.path_executor.follow_path()\n\n        # Check if goal reached\n        if self.path_executor.is_goal_reached():\n            return RobotState.IDLE\n\n        # Check for emergency stop\n        if sensors_data.get(\'emergency_stop\', False):\n            self.path_executor.stop_motion()\n            return RobotState.EMERGENCY_STOP\n\n        # Check if goal was canceled\n        if not robot.has_active_goal():\n            self.path_executor.stop_motion()\n            return RobotState.IDLE\n\n        return RobotState.NAVIGATING\n\nclass ManipulatingState(State):\n    """Robot is performing manipulation task"""\n\n    def __init__(self):\n        super().__init__(RobotState.MANIPULATING)\n        self.manipulation_executor = None\n        self.task_timeout = 60.0  # seconds\n\n    def enter(self, robot):\n        super().enter(robot)\n        # Initialize manipulation task\n        self.manipulation_executor = robot.get_manipulation_executor()\n        self.manipulation_executor.start_task(robot.get_current_task())\n\n    def execute(self, robot, sensors_data: Dict[str, Any]) -> RobotState:\n        # Execute manipulation\n        self.manipulation_executor.execute_step()\n\n        # Check if task completed\n        if self.manipulation_executor.is_task_completed():\n            return RobotState.IDLE\n\n        # Check for failure\n        if self.manipulation_executor.has_failed() or self.get_duration() > self.task_timeout:\n            # Handle failure - maybe retry or go to idle\n            robot.handle_manipulation_failure()\n            return RobotState.IDLE\n\n        # Check for emergency stop\n        if sensors_data.get(\'emergency_stop\', False):\n            self.manipulation_executor.stop_task()\n            return RobotState.EMERGENCY_STOP\n\n        return RobotState.MANIPULATING\n\nclass FSMController:\n    """Finite State Machine controller for robot"""\n\n    def __init__(self):\n        # Initialize states\n        self.states = {\n            RobotState.IDLE: IdleState(),\n            RobotState.NAVIGATING: NavigatingState(),\n            RobotState.MANIPULATING: ManipulatingState(),\n            # Add other states as needed\n        }\n\n        self.current_state = RobotState.IDLE\n        self.previous_state = None\n\n        # Initialize current state\n        self.active_state = self.states[self.current_state]\n        self.active_state.enter(None)  # robot will be passed during execution\n\n    def update(self, robot, sensors_data: Dict[str, Any]) -> RobotState:\n        """\n        Update FSM with sensor data and return next state\n\n        Args:\n            robot: Robot instance\n            sensors_data: Dictionary of sensor readings\n\n        Returns:\n            Current state\n        """\n        # Execute current state\n        next_state = self.active_state.execute(robot, sensors_data)\n\n        # Handle state transition if needed\n        if next_state != self.current_state:\n            # Exit current state\n            self.active_state.exit(robot)\n\n            # Update state\n            self.previous_state = self.current_state\n            self.current_state = next_state\n            self.active_state = self.states[next_state]\n\n            # Enter new state\n            self.active_state.enter(robot)\n\n        return self.current_state\n\n    def get_current_state(self) -> RobotState:\n        """Get current state"""\n        return self.current_state\n\n    def force_transition(self, new_state: RobotState):\n        """Force transition to a specific state"""\n        if new_state != self.current_state:\n            self.active_state.exit(None)\n            self.previous_state = self.current_state\n            self.current_state = new_state\n            self.active_state = self.states[new_state]\n            self.active_state.enter(None)\n\n# Example robot class that uses the FSM\nclass Robot:\n    """Example robot that uses FSM for decision making"""\n\n    def __init__(self):\n        self.fsm = FSMController()\n        self.navigation_goal = None\n        self.manipulation_task = None\n        self.battery_level = 100.0\n        self.charging_station_pos = (0, 0)\n\n    def has_navigation_goal(self) -> bool:\n        """Check if there\'s an active navigation goal"""\n        return self.navigation_goal is not None\n\n    def has_manipulation_task(self) -> bool:\n        """Check if there\'s an active manipulation task"""\n        return self.manipulation_task is not None\n\n    def needs_charging(self) -> bool:\n        """Check if robot needs charging"""\n        return self.battery_level < 20.0\n\n    def get_current_goal(self) -> tuple:\n        """Get current navigation goal"""\n        return self.navigation_goal\n\n    def has_active_goal(self) -> bool:\n        """Check if navigation goal is still active"""\n        return self.navigation_goal is not None\n\n    def cancel_navigation(self):\n        """Cancel current navigation goal"""\n        self.navigation_goal = None\n\n    def get_path_executor(self):\n        """Get path execution interface"""\n        # This would return a path executor object in a real implementation\n        return PathExecutor()\n\n    def get_manipulation_executor(self):\n        """Get manipulation execution interface"""\n        # This would return a manipulation executor in a real implementation\n        return ManipulationExecutor()\n\n    def get_current_task(self):\n        """Get current manipulation task"""\n        return self.manipulation_task\n\n    def handle_manipulation_failure(self):\n        """Handle manipulation task failure"""\n        print("Handling manipulation failure")\n        self.manipulation_task = None\n\n    def perform_periodic_tasks(self):\n        """Perform periodic tasks when idle"""\n        print("Performing periodic tasks...")\n        # Check battery, update map, etc.\n\n    def run(self):\n        """Main robot execution loop"""\n        # Simulate sensor data\n        sensors_data = {\n            \'obstacles\': [],\n            \'battery\': self.battery_level,\n            \'emergency_stop\': False\n        }\n\n        # Update FSM\n        current_state = self.fsm.update(self, sensors_data)\n        print(f"Current state: {current_state}")\n\n        return current_state\n\nclass PathExecutor:\n    """Placeholder for path execution functionality"""\n\n    def plan_to_goal(self, goal):\n        print(f"Planning to goal: {goal}")\n\n    def follow_path(self):\n        print("Following path...")\n\n    def has_obstacle_ahead(self, obstacles, threshold):\n        return len(obstacles) > 0  # Simplified\n\n    def is_goal_reached(self):\n        return False  # Simplified\n\n    def stop_motion(self):\n        print("Stopping motion")\n\n    def replan(self):\n        print("Replanning path...")\n\nclass ManipulationExecutor:\n    """Placeholder for manipulation execution functionality"""\n\n    def start_task(self, task):\n        print(f"Starting manipulation task: {task}")\n\n    def execute_step(self):\n        print("Executing manipulation step...")\n\n    def is_task_completed(self):\n        return False  # Simplified\n\n    def has_failed(self):\n        return False  # Simplified\n\n    def stop_task(self):\n        print("Stopping manipulation task")\n'})}),"\n",(0,i.jsx)(e.h3,{id:"behavior-trees-implementation",children:"Behavior Trees Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'from abc import ABC, abstractmethod\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\nimport time\n\nclass NodeStatus(Enum):\n    """Status of a behavior tree node"""\n    SUCCESS = "success"\n    FAILURE = "failure"\n    RUNNING = "running"\n\nclass BehaviorNode(ABC):\n    """Abstract base class for behavior tree nodes"""\n\n    def __init__(self, name: str):\n        self.name = name\n        self.status = NodeStatus.RUNNING\n        self.children: List[\'BehaviorNode\'] = []\n        self.blackboard: Dict[str, Any] = {}\n\n    @abstractmethod\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """\n        Execute one cycle of the node\n\n        Args:\n            blackboard: Shared memory for the behavior tree\n\n        Returns:\n            Status of the node execution\n        """\n        pass\n\n    def add_child(self, child: \'BehaviorNode\'):\n        """Add a child node"""\n        self.children.append(child)\n\n    def reset(self):\n        """Reset node state"""\n        self.status = NodeStatus.RUNNING\n        for child in self.children:\n            child.reset()\n\nclass CompositeNode(BehaviorNode):\n    """Base class for nodes with children"""\n\n    def __init__(self, name: str):\n        super().__init__(name)\n        self.current_child_idx = 0\n\n    def reset(self):\n        super().reset()\n        self.current_child_idx = 0\n        for child in self.children:\n            child.reset()\n\nclass SequenceNode(CompositeNode):\n    """Sequence node: executes children in order until one fails"""\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        for i in range(self.current_child_idx, len(self.children)):\n            child = self.children[i]\n            child_status = child.tick(blackboard)\n\n            if child_status == NodeStatus.FAILURE:\n                self.current_child_idx = 0  # Reset for next time\n                return NodeStatus.FAILURE\n            elif child_status == NodeStatus.RUNNING:\n                self.current_child_idx = i\n                return NodeStatus.RUNNING\n            # If SUCCESS, continue to next child\n\n        # All children succeeded\n        self.current_child_idx = 0\n        return NodeStatus.SUCCESS\n\nclass SelectorNode(CompositeNode):\n    """Selector node: executes children in order until one succeeds"""\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        for i in range(self.current_child_idx, len(self.children)):\n            child = self.children[i]\n            child_status = child.tick(blackboard)\n\n            if child_status == NodeStatus.SUCCESS:\n                self.current_child_idx = 0  # Reset for next time\n                return NodeStatus.SUCCESS\n            elif child_status == NodeStatus.RUNNING:\n                self.current_child_idx = i\n                return NodeStatus.RUNNING\n            # If FAILURE, continue to next child\n\n        # All children failed\n        self.current_child_idx = 0\n        return NodeStatus.FAILURE\n\nclass DecoratorNode(BehaviorNode):\n    """Decorator node: modifies behavior of a single child"""\n\n    def __init__(self, name: str, child: BehaviorNode):\n        super().__init__(name)\n        self.child = child\n\n    def reset(self):\n        super().reset()\n        self.child.reset()\n\nclass InverterNode(DecoratorNode):\n    """Inverter decorator: inverts the result of its child"""\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        child_status = self.child.tick(blackboard)\n\n        if child_status == NodeStatus.SUCCESS:\n            return NodeStatus.FAILURE\n        elif child_status == NodeStatus.FAILURE:\n            return NodeStatus.SUCCESS\n        else:\n            return NodeStatus.RUNNING\n\nclass RepeatNode(DecoratorNode):\n    """Repeat decorator: repeats child execution a specified number of times"""\n\n    def __init__(self, name: str, child: BehaviorNode, num_repeats: int):\n        super().__init__(name, child)\n        self.num_repeats = num_repeats\n        self.count = 0\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        while self.count < self.num_repeats:\n            child_status = self.child.tick(blackboard)\n\n            if child_status == NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            elif child_status == NodeStatus.FAILURE:\n                self.count = 0\n                return NodeStatus.FAILURE\n\n            # Child succeeded, increment counter\n            self.count += 1\n\n            if self.count >= self.num_repeats:\n                self.count = 0\n                return NodeStatus.SUCCESS\n\n        # Should not reach here normally\n        self.count = 0\n        return NodeStatus.SUCCESS\n\nclass ActionNode(BehaviorNode):\n    """Leaf node that performs an action"""\n\n    def __init__(self, name: str, action_func):\n        super().__init__(name)\n        self.action_func = action_func\n        self.start_time = None\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        # Call the action function\n        result = self.action_func(blackboard)\n        return result\n\nclass ConditionNode(BehaviorNode):\n    """Leaf node that checks a condition"""\n\n    def __init__(self, name: str, condition_func):\n        super().__init__(name)\n        self.condition_func = condition_func\n\n    def tick(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        # Call the condition function\n        if self.condition_func(blackboard):\n            return NodeStatus.SUCCESS\n        else:\n            return NodeStatus.FAILURE\n\nclass RobotBehaviorTree:\n    """Complete behavior tree for robot decision making"""\n\n    def __init__(self):\n        self.root = self.build_tree()\n        self.blackboard = {\n            \'battery_level\': 80.0,\n            \'goal_reached\': False,\n            \'obstacle_detected\': False,\n            \'object_detected\': False,\n            \'gripper_empty\': True\n        }\n\n    def build_tree(self) -> BehaviorNode:\n        """\n        Build the robot behavior tree\n        Root: Selector (try different behaviors)\n        """\n        # Main selector - tries different behaviors in order\n        main_selector = SelectorNode("Main_Behaviors")\n\n        # Emergency behavior: Stop if battery is low\n        battery_check = ConditionNode("Battery_Low", lambda bb: bb[\'battery_level\'] < 10.0)\n        emergency_stop = ActionNode("Emergency_Stop", self.emergency_stop)\n        battery_sequence = SequenceNode("Battery_Check_Sequence")\n        battery_sequence.add_child(battery_check)\n        battery_sequence.add_child(emergency_stop)\n\n        # Navigation behavior\n        has_goal = ConditionNode("Has_Navigation_Goal", lambda bb: not bb[\'goal_reached\'])\n        navigate_to_goal = ActionNode("Navigate_To_Goal", self.navigate_to_goal)\n        navigation_sequence = SequenceNode("Navigation_Sequence")\n        navigation_sequence.add_child(has_goal)\n        navigation_sequence.add_child(navigate_to_goal)\n\n        # Charging behavior\n        needs_charging = ConditionNode("Needs_Charging", lambda bb: bb[\'battery_level\'] < 20.0)\n        move_to_charger = ActionNode("Move_To_Charger", self.move_to_charger)\n        start_charging = ActionNode("Start_Charging", self.start_charging)\n        charging_sequence = SequenceNode("Charging_Sequence")\n        charging_sequence.add_child(needs_charging)\n        charging_sequence.add_child(move_to_charger)\n        charging_sequence.add_child(start_charging)\n\n        # Patrol behavior (default)\n        patrol_action = ActionNode("Patrol", self.patrol)\n        patrol_sequence = SequenceNode("Patrol_Sequence")\n        patrol_sequence.add_child(patrol_action)\n\n        # Add all sequences to main selector\n        main_selector.add_child(battery_sequence)\n        main_selector.add_child(charging_sequence)\n        main_selector.add_child(navigation_sequence)\n        main_selector.add_child(patrol_sequence)\n\n        return main_selector\n\n    def emergency_stop(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """Emergency stop action"""\n        print("EMERGENCY STOP!")\n        # Actually stop the robot\n        blackboard[\'robot_stopped\'] = True\n        return NodeStatus.SUCCESS\n\n    def navigate_to_goal(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """Navigate to goal action"""\n        print("Navigating to goal...")\n        # Simulate navigation\n        # In real implementation, this would call navigation stack\n        blackboard[\'goal_reached\'] = True  # For simulation\n        return NodeStatus.SUCCESS\n\n    def move_to_charger(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """Move to charger action"""\n        print("Moving to charging station...")\n        # Simulate movement to charger\n        return NodeStatus.SUCCESS\n\n    def start_charging(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """Start charging action"""\n        print("Starting to charge...")\n        # Simulate charging\n        blackboard[\'battery_level\'] = min(100.0, blackboard[\'battery_level\'] + 10.0)\n        return NodeStatus.SUCCESS\n\n    def patrol(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        """Patrol action"""\n        print("Patrolling area...")\n        # Simulate patrol behavior\n        return NodeStatus.SUCCESS\n\n    def update(self) -> NodeStatus:\n        """Update the behavior tree"""\n        return self.root.tick(self.blackboard)\n\n    def reset(self):\n        """Reset the behavior tree"""\n        self.root.reset()\n\n# Example usage\ndef example_behavior_tree():\n    bt = RobotBehaviorTree()\n\n    # Simulate several cycles\n    for i in range(10):\n        print(f"\\nCycle {i+1}:")\n        status = bt.update()\n        print(f"Tree status: {status}")\n        print(f"Blackboard: {bt.blackboard}")\n\n        # Modify blackboard for next cycle\n        bt.blackboard[\'battery_level\'] -= 2.0\n        bt.blackboard[\'goal_reached\'] = False\n\nclass TaskPlanner:\n    """High-level task planner that creates behavior trees for complex tasks"""\n\n    def __init__(self):\n        self.known_tasks = {\n            \'pick_and_place\': self.create_pick_and_place_tree,\n            \'room_cleaning\': self.create_room_cleaning_tree,\n            \'delivery\': self.create_delivery_tree,\n            \'patrol\': self.create_patrol_tree\n        }\n\n    def create_pick_and_place_tree(self) -> BehaviorNode:\n        """Create behavior tree for pick and place task"""\n        # Sequence: Navigate to object -> Pick up -> Navigate to goal -> Place\n        main_sequence = SequenceNode("Pick_And_Place_Main")\n\n        # Navigate to object\n        navigate_to_obj = ActionNode("Navigate_To_Object", self.navigate_to_object)\n        main_sequence.add_child(navigate_to_obj)\n\n        # Grasp object\n        grasp_obj = ActionNode("Grasp_Object", self.grasp_object)\n        main_sequence.add_child(grasp_obj)\n\n        # Navigate to goal\n        navigate_to_goal = ActionNode("Navigate_To_Goal", self.navigate_to_goal)\n        main_sequence.add_child(navigate_to_goal)\n\n        # Release object\n        release_obj = ActionNode("Release_Object", self.release_object)\n        main_sequence.add_child(release_obj)\n\n        return main_sequence\n\n    def create_room_cleaning_tree(self) -> BehaviorNode:\n        """Create behavior tree for room cleaning task"""\n        # Selector: If dirty spot detected -> clean it, else -> continue patrolling\n        cleaning_selector = SelectorNode("Room_Cleaning")\n\n        # Clean detected spot\n        spot_detected = ConditionNode("Spot_Detected", lambda bb: bb.get(\'dirty_spot_detected\', False))\n        clean_spot = ActionNode("Clean_Spot", self.clean_spot)\n        spot_cleaning_seq = SequenceNode("Spot_Cleaning_Sequence")\n        spot_cleaning_seq.add_child(spot_detected)\n        spot_cleaning_seq.add_child(clean_spot)\n\n        # Continue cleaning\n        continue_cleaning = ActionNode("Continue_Cleaning", self.continue_cleaning)\n\n        cleaning_selector.add_child(spot_cleaning_seq)\n        cleaning_selector.add_child(continue_cleaning)\n\n        return cleaning_selector\n\n    def plan_task(self, task_name: str, params: Dict[str, Any] = None) -> Optional[BehaviorNode]:\n        """Plan a task by creating appropriate behavior tree"""\n        if task_name in self.known_tasks:\n            return self.known_tasks[task_name]()\n        else:\n            print(f"Unknown task: {task_name}")\n            return None\n\n    def navigate_to_object(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        print("Navigating to object...")\n        return NodeStatus.SUCCESS\n\n    def grasp_object(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        print("Grasping object...")\n        blackboard[\'gripper_empty\'] = False\n        return NodeStatus.SUCCESS\n\n    def release_object(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        print("Releasing object...")\n        blackboard[\'gripper_empty\'] = True\n        return NodeStatus.SUCCESS\n\n    def clean_spot(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        print("Cleaning detected spot...")\n        blackboard[\'dirty_spot_detected\'] = False\n        return NodeStatus.SUCCESS\n\n    def continue_cleaning(self, blackboard: Dict[str, Any]) -> NodeStatus:\n        print("Continuing cleaning routine...")\n        return NodeStatus.SUCCESS\n\n# Example of using the task planner\ndef example_task_planning():\n    planner = TaskPlanner()\n\n    # Plan a pick and place task\n    pick_place_tree = planner.plan_task(\'pick_and_place\')\n\n    if pick_place_tree:\n        print("Executing pick and place task...")\n        # Execute the tree for a few cycles\n        blackboard = {\'gripper_empty\': True, \'object_grasped\': False}\n\n        for i in range(4):\n            status = pick_place_tree.tick(blackboard)\n            print(f"Cycle {i+1}: Status = {status}, Blackboard = {blackboard}")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"urdf-examples",children:"URDF Examples"}),"\n",(0,i.jsx)(e.h3,{id:"robot-with-planning-capabilities",children:"Robot with Planning Capabilities"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="planning_robot">\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <cylinder radius="0.3" length="0.15"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0.0 0.0 1.0 1.0"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="0.3" length="0.15"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="15.0"/>\n      <inertia ixx="0.5" ixy="0.0" ixz="0.0" iyy="0.5" iyz="0.0" izz="0.3"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Wheels --\x3e\n  <joint name="wheel_left_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="wheel_left"/>\n    <origin xyz="0 0.25 -0.05" rpy="0 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="wheel_left">\n    <visual>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0.0 0.0 0.0 1.0"/>\n      </material>\n    </visual>\n  </link>\n\n  <joint name="wheel_right_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="wheel_right"/>\n    <origin xyz="0 -0.25 -0.05" rpy="0 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="wheel_right">\n    <visual>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0.0 0.0 0.0 1.0"/>\n      </material>\n    </visual>\n  </link>\n\n  \x3c!-- Planning Sensors --\x3e\n  <joint name="lidar_mount_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="lidar_link"/>\n    <origin xyz="0.0 0.0 0.2" rpy="0 0 0"/>\n  </joint>\n\n  <link name="lidar_link">\n    <visual>\n      <geometry>\n        <cylinder radius="0.05" length="0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  <joint name="camera_mount_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_link"/>\n    <origin xyz="0.2 0.0 0.15" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  \x3c!-- Planning Controller --\x3e\n  <gazebo reference="base_link">\n    <plugin name="planning_controller" filename="libplanning_controller.so">\n      <command_topic>planning_commands</command_topic>\n      <feedback_topic>planning_feedback</feedback_topic>\n      <lidar_topic>scan</lidar_topic>\n      <camera_topic>camera/image_raw</camera_topic>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- LIDAR Sensor --\x3e\n  <gazebo reference="lidar_link">\n    <sensor name="lidar" type="ray">\n      <always_on>true</always_on>\n      <update_rate>10</update_rate>\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>360</samples>\n            <resolution>1.0</resolution>\n            <min_angle>-3.14159</min_angle>\n            <max_angle>3.14159</max_angle>\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.1</min>\n          <max>10.0</max>\n          <resolution>0.01</resolution>\n        </range>\n      </ray>\n      <plugin name="lidar_controller" filename="libgazebo_ros_ray_sensor.so">\n        <frame_name>lidar_link</frame_name>\n        <topic_name>scan</topic_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- Camera Sensor --\x3e\n  <gazebo reference="camera_link">\n    <sensor name="camera" type="camera">\n      <always_on>true</always_on>\n      <update_rate>30</update_rate>\n      <camera>\n        <horizontal_fov>1.047</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>10</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <frame_name>camera_link</frame_name>\n        <topic_name>camera/image_raw</topic_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- Differential Drive Controller --\x3e\n  <gazebo>\n    <plugin name="diff_drive" filename="libgazebo_ros_diff_drive.so">\n      <left_joint>wheel_left_joint</left_joint>\n      <right_joint>wheel_right_joint</right_joint>\n      <wheel_separation>0.5</wheel_separation>\n      <wheel_diameter>0.2</wheel_diameter>\n      <command_topic>cmd_vel</command_topic>\n      <odometry_topic>odom</odometry_topic>\n      <odometry_frame>odom</odometry_frame>\n      <robot_base_frame>base_link</robot_base_frame>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Planning Algorithms Plugin --\x3e\n  <gazebo reference="base_link">\n    <plugin name="planning_algorithms" filename="libplanning_algorithms.so">\n      <algorithm>a_star</algorithm>\n      <map_resolution>0.05</map_resolution>\n      <inflation_radius>0.5</inflation_radius>\n      <topic_prefix>planning</topic_prefix>\n    </plugin>\n  </gazebo>\n</robot>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"planning-algorithm-comparison",children:"Planning Algorithm Comparison"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Algorithm"}),(0,i.jsx)(e.th,{children:"Completeness"}),(0,i.jsx)(e.th,{children:"Optimality"}),(0,i.jsx)(e.th,{children:"Time Complexity"}),(0,i.jsx)(e.th,{children:"Space Complexity"}),(0,i.jsx)(e.th,{children:"Best Use Case"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"A*"}),(0,i.jsx)(e.td,{children:"Complete"}),(0,i.jsx)(e.td,{children:"Optimal"}),(0,i.jsx)(e.td,{children:"O(b^d)"}),(0,i.jsx)(e.td,{children:"O(b^d)"}),(0,i.jsx)(e.td,{children:"Static environments with good heuristics"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Dijkstra"}),(0,i.jsx)(e.td,{children:"Complete"}),(0,i.jsx)(e.td,{children:"Optimal"}),(0,i.jsx)(e.td,{children:"O(V\xb2) or O(E + V log V)"}),(0,i.jsx)(e.td,{children:"O(V)"}),(0,i.jsx)(e.td,{children:"Uniform cost grids"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"RRT"}),(0,i.jsx)(e.td,{children:"Probabilistically Complete"}),(0,i.jsx)(e.td,{children:"Not Optimal"}),(0,i.jsx)(e.td,{children:"O(n) per iteration"}),(0,i.jsx)(e.td,{children:"O(n)"}),(0,i.jsx)(e.td,{children:"High-dimensional spaces, kinodynamic planning"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"RRT*"}),(0,i.jsx)(e.td,{children:"Asymptotically Optimal"}),(0,i.jsx)(e.td,{children:"Optimal as n\u2192\u221e"}),(0,i.jsx)(e.td,{children:"O(n) per iteration"}),(0,i.jsx)(e.td,{children:"O(n)"}),(0,i.jsx)(e.td,{children:"Optimal motion planning"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"PRM"}),(0,i.jsx)(e.td,{children:"Probabilistically Complete"}),(0,i.jsx)(e.td,{children:"Not Optimal"}),(0,i.jsx)(e.td,{children:"O(kn\xb2) for query"}),(0,i.jsx)(e.td,{children:"O(n)"}),(0,i.jsx)(e.td,{children:"Multiple queries in same map"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"D* Lite"}),(0,i.jsx)(e.td,{children:"Complete"}),(0,i.jsx)(e.td,{children:"Optimal"}),(0,i.jsx)(e.td,{children:"O(n\xb2) worst case"}),(0,i.jsx)(e.td,{children:"O(n)"}),(0,i.jsx)(e.td,{children:"Dynamic/replanning environments"})]})]})]}),"\n",(0,i.jsx)(e.h2,{id:"behavior-tree-elements",children:"Behavior Tree Elements"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-mermaid",children:"graph TD\n    A[Root Selector] --\x3e B[Emergency Check]\n    A --\x3e C[Navigation Task]\n    A --\x3e D[Charging Task]\n    A --\x3e E[Patrol Task]\n\n    B --\x3e B1{Battery < 10%}\n    B1 --\x3e|Yes| B2[Stop Robot]\n    B1 --\x3e|No| B3[Continue]\n\n    C --\x3e C1{Has Goal}\n    C1 --\x3e|Yes| C2[Navigate to Goal]\n    C1 --\x3e|No| C3[Wait]\n\n    D --\x3e D1{Battery < 20%}\n    D1 --\x3e|Yes| D2[Go to Charger]\n    D1 --\x3e|Yes| D3[Charge Battery]\n    D1 --\x3e|No| D4[Continue]\n\n    E --\x3e E1[Patrol Area]\n\n    style A fill:#99ccff\n    style B fill:#ff9999\n    style C fill:#ff9999\n    style D fill:#ff9999\n    style E fill:#ff9999\n"})}),"\n",(0,i.jsx)(e.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Planning"}),": Process of determining a sequence of actions to achieve a goal"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Path Planning"}),": Finding geometric path from start to goal"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Motion Planning"}),": Finding path considering robot dynamics and constraints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Task Planning"}),": High-level sequencing of actions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Reactive Planning"}),": Immediate response to environmental changes"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Deliberative Planning"}),": Careful consideration of multiple alternatives"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Anytime Algorithm"}),": Algorithm that can return valid solution at any time"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Probabilistic Completeness"}),": Algorithm finds solution if one exists given enough time"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Asymptotic Optimality"}),": Solution quality improves with computation time"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Configuration Space"}),": Space of all possible robot configurations"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Free Space"}),": Subset of configuration space where robot doesn't collide"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"C-obstacle"}),": Region in configuration space where robot collides with obstacles"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"learning-checkpoints",children:"Learning Checkpoints"}),"\n",(0,i.jsx)(e.h3,{id:"quiz-questions",children:"Quiz Questions"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"What is the main difference between A* and Dijkstra's algorithm?"}),"\n",(0,i.jsx)(e.li,{children:"When would you choose RRT over A* for path planning?"}),"\n",(0,i.jsx)(e.li,{children:"Explain the difference between sequence and selector nodes in behavior trees."}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,i.jsx)(e.p,{children:"Implement a hybrid planning approach that uses A* for global path planning and RRT for local obstacle avoidance."}),"\n",(0,i.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,i.jsx)(e.p,{children:"Create a complete behavior tree that implements a robot's daily routine including navigation, manipulation, charging, and emergency handling. Test the tree with different environmental conditions."}),"\n",(0,i.jsx)(e.h2,{id:"personalization",children:"Personalization"}),"\n",(0,i.jsxs)("div",{className:"personalization-options",children:[(0,i.jsx)("h3",{children:"Adjust Learning Path:"}),(0,i.jsx)("button",{onClick:()=>setDifficulty("beginner"),children:"Beginner"}),(0,i.jsx)("button",{onClick:()=>setDifficulty("intermediate"),children:"Intermediate"}),(0,i.jsx)("button",{onClick:()=>setDifficulty("advanced"),children:"Advanced"})]}),"\n",(0,i.jsx)(e.h2,{id:"translation",children:"Translation"}),"\n",(0,i.jsx)("div",{className:"translation-controls",children:(0,i.jsx)("button",{onClick:()=>translateToUrdu(),children:"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u062a\u0631\u062c\u0645\u06c1 \u06a9\u0631\u06cc\u06ba"})})]})}function _(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>s});var a=t(6540);const i={},o=a.createContext(i);function r(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:r(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);