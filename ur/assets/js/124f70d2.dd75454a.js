"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[5911],{7669:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"weekly-breakdown/week12/index","title":"Week 12: Integration and Deployment","description":"Learning Objectives","source":"@site/docs/weekly-breakdown/week12/index.mdx","sourceDirName":"weekly-breakdown/week12","slug":"/weekly-breakdown/week12/","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week12/","draft":false,"unlisted":false,"editUrl":"https://github.com/fatima317/physical-ai-book/tree/main/docs/weekly-breakdown/week12/index.mdx","tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12},"sidebar":"tutorialSidebar","previous":{"title":"Week 11 - AI Planning and Decision Making","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week11/"},"next":{"title":"Week 13: Advanced Topics and Future Directions","permalink":"/physical-ai-book/ur/docs/weekly-breakdown/week13/"}}');var a=s(4848),r=s(8453);const i={sidebar_position:12},o="Week 12: Integration and Deployment",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"System Integration",id:"system-integration",level:2},{value:"System Monitoring",id:"system-monitoring",level:2},{value:"Deployment Strategies",id:"deployment-strategies",level:2},{value:"Containerized Deployment with Docker",id:"containerized-deployment-with-docker",level:3},{value:"Kubernetes for Multi-Robot Systems",id:"kubernetes-for-multi-robot-systems",level:3},{value:"Over-the-Air (OTA) Updates",id:"over-the-air-ota-updates",level:3},{value:"Key Terms",id:"key-terms",level:2},{value:"Learning Checkpoints",id:"learning-checkpoints",level:2},{value:"Summary",id:"summary",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"week-12-integration-and-deployment",children:"Week 12: Integration and Deployment"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this week, students will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Integrate multiple robotics subsystems into a cohesive system"}),"\n",(0,a.jsx)(n.li,{children:"Implement deployment strategies for physical AI systems"}),"\n",(0,a.jsx)(n.li,{children:"Monitor and maintain deployed systems"}),"\n",(0,a.jsx)(n.li,{children:"Handle system failures and recovery procedures"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"system-integration",children:"System Integration"}),"\n",(0,a.jsx)(n.p,{children:"In this section, we'll implement the SystemIntegrator class that coordinates between different subsystems:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nSystem Integration Manager for Physical AI\nHandles coordination between perception, planning, and control systems\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nfrom geometry_msgs.msg import Twist, Pose\nfrom sensor_msgs.msg import JointState\nfrom rcl_interfaces.msg import ParameterDescriptor\nimport time\nimport threading\nfrom collections import deque\nimport json\n\nclass SystemIntegrator(Node):\n    def __init__(self):\n        super().__init__('system_integrator')\n\n        # Subsystem status tracking\n        self.subsystem_status = {\n            'perception': False,\n            'planning': False,\n            'control': False,\n            'navigation': False\n        }\n\n        # Publishers for each subsystem\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, '/joint_commands', 10)\n        self.status_pub = self.create_publisher(String, '/system_status', 10)\n\n        # Subscribers for subsystem status\n        self.perception_sub = self.create_subscription(\n            Bool, '/perception/ready', self.perception_callback, 10)\n        self.planning_sub = self.create_subscription(\n            Bool, '/planning/ready', self.planning_callback, 10)\n        self.control_sub = self.create_subscription(\n            Bool, '/control/ready', self.control_callback, 10)\n        self.nav_sub = self.create_subscription(\n            Bool, '/navigation/ready', self.navigation_callback, 10)\n\n        # Service clients for subsystems\n        self.integration_timer = self.create_timer(1.0, self.integration_callback)\n\n        # System state tracking\n        self.system_state = 'IDLE'\n        self.task_queue = deque()\n\n        self.get_logger().info('System Integrator initialized')\n\n    def perception_callback(self, msg):\n        self.subsystem_status['perception'] = msg.data\n        self.get_logger().info(f'Perception subsystem status: {msg.data}')\n\n    def planning_callback(self, msg):\n        self.subsystem_status['planning'] = msg.data\n        self.get_logger().info(f'Planning subsystem status: {msg.data}')\n\n    def control_callback(self, msg):\n        self.subsystem_status['control'] = msg.data\n        self.get_logger().info(f'Control subsystem status: {msg.data}')\n\n    def navigation_callback(self, msg):\n        self.subsystem_status['navigation'] = msg.data\n        self.get_logger().info(f'Navigation subsystem status: {msg.data}')\n\n    def integration_callback(self):\n        # Check if all subsystems are ready\n        all_ready = all(self.subsystem_status.values())\n\n        if all_ready and self.system_state == 'IDLE':\n            self.system_state = 'READY'\n            status_msg = String()\n            status_msg.data = 'SYSTEM_READY'\n            self.status_pub.publish(status_msg)\n            self.get_logger().info('All subsystems ready - system operational')\n        elif not all_ready:\n            self.system_state = 'IDLE'\n            status_msg = String()\n            status_msg.data = 'SYSTEM_WAITING'\n            self.status_pub.publish(status_msg)\n\n    def execute_task(self, task):\n        \"\"\"Execute a high-level task using integrated subsystems\"\"\"\n        if self.system_state != 'READY':\n            self.get_logger().error('System not ready for task execution')\n            return False\n\n        # Add task to queue\n        self.task_queue.append(task)\n\n        # Process tasks in queue\n        while self.task_queue:\n            current_task = self.task_queue.popleft()\n            self.process_task(current_task)\n\n        return True\n\n    def process_task(self, task):\n        \"\"\"Process individual tasks using appropriate subsystems\"\"\"\n        task_type = task.get('type', '')\n\n        if task_type == 'navigate':\n            self.execute_navigation_task(task)\n        elif task_type == 'manipulate':\n            self.execute_manipulation_task(task)\n        elif task_type == 'perceive':\n            self.execute_perception_task(task)\n        else:\n            self.get_logger().error(f'Unknown task type: {task_type}')\n\n    def execute_navigation_task(self, task):\n        \"\"\"Execute navigation task using integrated systems\"\"\"\n        goal = task.get('goal', {})\n        self.get_logger().info(f'Executing navigation task to {goal}')\n\n        # Send navigation command\n        cmd_vel = Twist()\n        cmd_vel.linear.x = goal.get('linear_x', 0.0)\n        cmd_vel.angular.z = goal.get('angular_z', 0.0)\n        self.cmd_vel_pub.publish(cmd_vel)\n\n    def execute_manipulation_task(self, task):\n        \"\"\"Execute manipulation task using integrated systems\"\"\"\n        joints = task.get('joints', {})\n        self.get_logger().info(f'Executing manipulation task with joints {joints}')\n\n        # Send joint commands\n        joint_cmd = JointState()\n        joint_cmd.name = list(joints.keys())\n        joint_cmd.position = list(joints.values())\n        self.joint_cmd_pub.publish(joint_cmd)\n\n    def execute_perception_task(self, task):\n        \"\"\"Execute perception task using integrated systems\"\"\"\n        target = task.get('target', '')\n        self.get_logger().info(f'Executing perception task for {target}')\n\n        # Trigger perception system\n        perception_cmd = String()\n        perception_cmd.data = f'DETECT_{target.upper()}'\n        # Additional logic would go here to trigger perception subsystem\n\ndef main(args=None):\n    rclpy.init(args=args)\n    integrator = SystemIntegrator()\n\n    try:\n        rclpy.spin(integrator)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        integrator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"system-monitoring",children:"System Monitoring"}),"\n",(0,a.jsx)(n.p,{children:"Now let's implement a SystemMonitor class to track the health and performance of our integrated system:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nSystem Monitor for Physical AI\nMonitors system health, performance, and resource usage\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Float32\nfrom diagnostic_msgs.msg import DiagnosticArray, DiagnosticStatus\nfrom sensor_msgs.msg import BatteryState\nimport psutil\nimport time\nimport threading\nfrom collections import deque\nimport json\n\nclass SystemMonitor(Node):\n    def __init__(self):\n        super().__init__('system_monitor')\n\n        # Publishers for monitoring data\n        self.diag_pub = self.create_publisher(DiagnosticArray, '/diagnostics', 10)\n        self.cpu_pub = self.create_publisher(Float32, '/system/cpu_usage', 10)\n        self.mem_pub = self.create_publisher(Float32, '/system/memory_usage', 10)\n        self.battery_pub = self.create_publisher(BatteryState, '/system/battery', 10)\n\n        # Monitoring timers\n        self.monitoring_timer = self.create_timer(2.0, self.monitor_system)\n        self.diag_timer = self.create_timer(5.0, self.publish_diagnostics)\n\n        # Performance tracking\n        self.cpu_history = deque(maxlen=50)\n        self.mem_history = deque(maxlen=50)\n        self.performance_threshold = 80.0  # Percentage threshold\n\n        # System status\n        self.system_status = 'OK'\n        self.last_update_time = time.time()\n\n        self.get_logger().info('System Monitor initialized')\n\n    def monitor_system(self):\n        \"\"\"Monitor system resources and performance\"\"\"\n        current_time = time.time()\n\n        # Get CPU usage\n        cpu_percent = psutil.cpu_percent(interval=None)\n        self.cpu_history.append(cpu_percent)\n        cpu_msg = Float32()\n        cpu_msg.data = float(cpu_percent)\n        self.cpu_pub.publish(cpu_msg)\n\n        # Get memory usage\n        memory = psutil.virtual_memory()\n        mem_percent = memory.percent\n        self.mem_history.append(mem_percent)\n        mem_msg = Float32()\n        mem_msg.data = float(mem_percent)\n        self.mem_pub.publish(mem_msg)\n\n        # Check for performance issues\n        avg_cpu = sum(self.cpu_history) / len(self.cpu_history) if self.cpu_history else 0\n        avg_mem = sum(self.mem_history) / len(self.mem_history) if self.mem_history else 0\n\n        if avg_cpu > self.performance_threshold or avg_mem > self.performance_threshold:\n            self.system_status = 'WARNING'\n            self.get_logger().warn(f'High resource usage - CPU: {avg_cpu:.1f}%, Memory: {avg_mem:.1f}%')\n        else:\n            self.system_status = 'OK'\n\n        # Update last update time\n        self.last_update_time = current_time\n\n        self.get_logger().debug(f'System monitor - CPU: {cpu_percent:.1f}%, Memory: {mem_percent:.1f}%')\n\n    def publish_diagnostics(self):\n        \"\"\"Publish diagnostic information\"\"\"\n        diag_array = DiagnosticArray()\n        diag_array.header.stamp = self.get_clock().now().to_msg()\n\n        # CPU diagnostic\n        cpu_diag = DiagnosticStatus()\n        cpu_diag.name = 'CPU Monitor'\n        cpu_diag.hardware_id = 'cpu0'\n        cpu_avg = sum(self.cpu_history) / len(self.cpu_history) if self.cpu_history else 0\n        cpu_diag.values.append({'key': 'CPU Usage (%)', 'value': f'{cpu_avg:.1f}'})\n\n        if cpu_avg > self.performance_threshold:\n            cpu_diag.level = DiagnosticStatus.WARN\n            cpu_diag.message = f'High CPU usage: {cpu_avg:.1f}%'\n        else:\n            cpu_diag.level = DiagnosticStatus.OK\n            cpu_diag.message = f'Normal CPU usage: {cpu_avg:.1f}%'\n\n        diag_array.status.append(cpu_diag)\n\n        # Memory diagnostic\n        mem_diag = DiagnosticStatus()\n        mem_diag.name = 'Memory Monitor'\n        mem_diag.hardware_id = 'memory'\n        mem_avg = sum(self.mem_history) / len(self.mem_history) if self.mem_history else 0\n        mem_diag.values.append({'key': 'Memory Usage (%)', 'value': f'{mem_avg:.1f}'})\n\n        if mem_avg > self.performance_threshold:\n            mem_diag.level = DiagnosticStatus.WARN\n            mem_diag.message = f'High memory usage: {mem_avg:.1f}%'\n        else:\n            mem_diag.level = DiagnosticStatus.OK\n            mem_diag.message = f'Normal memory usage: {mem_avg:.1f}%'\n\n        diag_array.status.append(mem_diag)\n\n        # System status diagnostic\n        sys_diag = DiagnosticStatus()\n        sys_diag.name = 'System Status'\n        sys_diag.hardware_id = 'system'\n        sys_diag.values.append({'key': 'Status', 'value': self.system_status})\n        sys_diag.values.append({'key': 'Last Update', 'value': f'{self.last_update_time:.0f}'})\n\n        if self.system_status == 'WARNING':\n            sys_diag.level = DiagnosticStatus.WARN\n            sys_diag.message = 'System experiencing high resource usage'\n        else:\n            sys_diag.level = DiagnosticStatus.OK\n            sys_diag.message = 'System operating normally'\n\n        diag_array.status.append(sys_diag)\n\n        self.diag_pub.publish(diag_array)\n        self.get_logger().debug(f'Published diagnostics - System status: {self.system_status}')\n\n    def get_system_health(self):\n        \"\"\"Get overall system health status\"\"\"\n        return {\n            'status': self.system_status,\n            'cpu_usage': sum(self.cpu_history) / len(self.cpu_history) if self.cpu_history else 0,\n            'memory_usage': sum(self.mem_history) / len(self.mem_history) if self.mem_history else 0,\n            'last_update': self.last_update_time\n        }\n\ndef main(args=None):\n    rclpy.init(args=args)\n    monitor = SystemMonitor()\n\n    try:\n        rclpy.spin(monitor)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        monitor.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"deployment-strategies",children:"Deployment Strategies"}),"\n",(0,a.jsx)(n.p,{children:"Deployment of Physical AI systems requires careful consideration of hardware constraints, real-time performance requirements, and safety considerations. Here are key strategies:"}),"\n",(0,a.jsx)(n.h3,{id:"containerized-deployment-with-docker",children:"Containerized Deployment with Docker"}),"\n",(0,a.jsx)(n.p,{children:"For consistent deployment across different hardware platforms, containerization is essential:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-dockerfile",children:'# Dockerfile for Physical AI System\nFROM ros:humble-ros-base-jammy\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    python3-pip \\\n    python3-dev \\\n    build-essential \\\n    libeigen3-dev \\\n    libopencv-dev \\\n    libpcl-dev \\\n    ros-humble-navigation2 \\\n    ros-humble-nav2-bringup \\\n    ros-humble-perception \\\n    ros-humble-rosbridge-suite \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set up workspace\nWORKDIR /workspace\nCOPY . /workspace/src\nRUN source /opt/ros/humble/setup.bash && \\\n    colcon build --packages-select physical_ai_system && \\\n    rm -rf build/ src/ log/\n\n# Source ROS environment\nRUN echo "source /opt/ros/humble/setup.bash" >> ~/.bashrc\nRUN echo "source /workspace/install/setup.bash" >> ~/.bashrc\n\n# Expose ports for ROS bridge\nEXPOSE 9090\n\n# Default command\nCMD ["bash", "-c", "source /opt/ros/humble/setup.bash && source /workspace/install/setup.bash && ros2 launch physical_ai_system system.launch.py"]\n'})}),"\n",(0,a.jsx)(n.h3,{id:"kubernetes-for-multi-robot-systems",children:"Kubernetes for Multi-Robot Systems"}),"\n",(0,a.jsx)(n.p,{children:"For managing fleets of robots, Kubernetes can orchestrate deployment and scaling:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# deployment.yaml - Kubernetes deployment for Physical AI robots\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: physical-ai-robot\n  namespace: robotics\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: physical-ai-robot\n  template:\n    metadata:\n      labels:\n        app: physical-ai-robot\n    spec:\n      containers:\n      - name: robot-system\n        image: physical-ai-system:latest\n        resources:\n          requests:\n            memory: "2Gi"\n            cpu: "1000m"\n          limits:\n            memory: "4Gi"\n            cpu: "2000m"\n        env:\n        - name: ROBOT_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: ROS_DOMAIN_ID\n          value: "1"\n        volumeMounts:\n        - name: robot-data\n          mountPath: /data\n        - name: robot-config\n          mountPath: /config\n      volumes:\n      - name: robot-data\n        persistentVolumeClaim:\n          claimName: robot-data-pvc\n      - name: robot-config\n        configMap:\n          name: robot-config\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: robot-service\n  namespace: robotics\nspec:\n  selector:\n    app: physical-ai-robot\n  ports:\n  - port: 9090\n    targetPort: 9090\n  type: LoadBalancer\n'})}),"\n",(0,a.jsx)(n.h3,{id:"over-the-air-ota-updates",children:"Over-the-Air (OTA) Updates"}),"\n",(0,a.jsx)(n.p,{children:"For remote system updates, implement a robust OTA update system:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nOTA Update Manager for Physical AI Systems\nHandles remote system updates with rollback capabilities\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nimport requests\nimport hashlib\nimport subprocess\nimport os\nimport shutil\nfrom threading import Thread\n\nclass OTAUpdateManager(Node):\n    def __init__(self):\n        super().__init__(\'ota_update_manager\')\n\n        self.update_status_pub = self.create_publisher(String, \'/ota/status\', 10)\n        self.update_available_sub = self.create_subscription(\n            String, \'/ota/check\', self.check_for_updates, 10)\n\n        # Configuration\n        self.update_server_url = "https://updates.physical-ai.example.com"\n        self.current_version = "1.0.0"\n        self.backup_path = "/backup"\n\n        self.get_logger().info(\'OTA Update Manager initialized\')\n\n    def check_for_updates(self, msg):\n        """Check for available updates"""\n        try:\n            response = requests.get(f"{self.update_server_url}/latest_version")\n            latest_version = response.json().get(\'version\', \'\')\n\n            if self.compare_versions(latest_version, self.current_version) > 0:\n                self.get_logger().info(f\'Update available: {latest_version}\')\n                self.download_update(latest_version)\n            else:\n                self.get_logger().info(\'System is up to date\')\n\n        except Exception as e:\n            self.get_logger().error(f\'Error checking for updates: {e}\')\n\n    def download_update(self, version):\n        """Download update package"""\n        try:\n            url = f"{self.update_server_url}/packages/{version}.tar.gz"\n            response = requests.get(url, stream=True)\n\n            update_file = f"/tmp/update_{version}.tar.gz"\n            with open(update_file, \'wb\') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n\n            # Verify checksum\n            checksum = self.calculate_checksum(update_file)\n            expected_checksum = self.get_expected_checksum(version)\n\n            if checksum == expected_checksum:\n                self.get_logger().info(f\'Update {version} downloaded and verified\')\n                self.install_update(update_file, version)\n            else:\n                self.get_logger().error(\'Checksum verification failed\')\n\n        except Exception as e:\n            self.get_logger().error(f\'Error downloading update: {e}\')\n\n    def install_update(self, update_file, version):\n        """Install the downloaded update"""\n        try:\n            # Create backup of current system\n            self.create_backup()\n\n            # Extract update\n            update_dir = f"/tmp/update_{version}"\n            os.makedirs(update_dir, exist_ok=True)\n            subprocess.run([\'tar\', \'-xzf\', update_file, \'-C\', update_dir])\n\n            # Stop current system\n            self.stop_system()\n\n            # Apply update\n            self.apply_update(update_dir)\n\n            # Verify update\n            if self.verify_update(version):\n                self.get_logger().info(f\'Update {version} installed successfully\')\n                self.current_version = version\n                self.cleanup(update_file, update_dir)\n            else:\n                self.get_logger().error(\'Update verification failed - rolling back\')\n                self.rollback_update()\n\n        except Exception as e:\n            self.get_logger().error(f\'Error installing update: {e}\')\n            self.rollback_update()\n\n    def create_backup(self):\n        """Create backup of current system"""\n        try:\n            if os.path.exists(self.backup_path):\n                shutil.rmtree(self.backup_path)\n            shutil.copytree(\'/workspace/install\', f\'{self.backup_path}/install\')\n            self.get_logger().info(\'Backup created successfully\')\n        except Exception as e:\n            self.get_logger().error(f\'Error creating backup: {e}\')\n\n    def stop_system(self):\n        """Stop the current system"""\n        try:\n            subprocess.run([\'systemctl\', \'stop\', \'physical-ai-system\'], check=True)\n            self.get_logger().info(\'System stopped for update\')\n        except subprocess.CalledProcessError:\n            self.get_logger().warn(\'Failed to stop system service\')\n\n    def apply_update(self, update_dir):\n        """Apply the update files"""\n        try:\n            # Copy new files\n            shutil.rmtree(\'/workspace/install\')\n            shutil.copytree(f\'{update_dir}/install\', \'/workspace/install\')\n            self.get_logger().info(\'Update applied successfully\')\n        except Exception as e:\n            self.get_logger().error(f\'Error applying update: {e}\')\n\n    def verify_update(self, version):\n        """Verify that the update was applied correctly"""\n        try:\n            # Check version file\n            version_file = \'/workspace/install/share/physical_ai_system/version.txt\'\n            if os.path.exists(version_file):\n                with open(version_file, \'r\') as f:\n                    installed_version = f.read().strip()\n                return installed_version == version\n            return False\n        except Exception:\n            return False\n\n    def rollback_update(self):\n        """Rollback to previous version"""\n        try:\n            if os.path.exists(f\'{self.backup_path}/install\'):\n                shutil.rmtree(\'/workspace/install\')\n                shutil.copytree(f\'{self.backup_path}/install\', \'/workspace/install\')\n                self.get_logger().info(\'Update rolled back successfully\')\n            else:\n                self.get_logger().error(\'No backup available for rollback\')\n        except Exception as e:\n            self.get_logger().error(f\'Error during rollback: {e}\')\n\n    def cleanup(self, update_file, update_dir):\n        """Clean up temporary files"""\n        try:\n            os.remove(update_file)\n            shutil.rmtree(update_dir)\n            self.get_logger().info(\'Cleanup completed\')\n        except Exception as e:\n            self.get_logger().warn(f\'Error during cleanup: {e}\')\n\n    def compare_versions(self, v1, v2):\n        """Compare two version strings"""\n        def normalize(v):\n            return [int(x) for x in v.split(".")]\n\n        n1, n2 = normalize(v1), normalize(v2)\n        return (n1 > n2) - (n1 < n2)\n\n    def calculate_checksum(self, file_path):\n        """Calculate MD5 checksum of file"""\n        hash_md5 = hashlib.md5()\n        with open(file_path, "rb") as f:\n            for chunk in iter(lambda: f.read(4096), b""):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n\n    def get_expected_checksum(self, version):\n        """Get expected checksum from server"""\n        try:\n            response = requests.get(f"{self.update_server_url}/checksums/{version}")\n            return response.json().get(\'checksum\', \'\')\n        except Exception as e:\n            self.get_logger().error(f\'Error getting checksum: {e}\')\n            return \'\'\n\ndef main(args=None):\n    rclpy.init(args=args)\n    updater = OTAUpdateManager()\n\n    try:\n        rclpy.spin(updater)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        updater.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"System Integration"}),": The process of combining individual subsystems into a unified system"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Deployment"}),": The process of installing and configuring software on target hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OTA Updates"}),": Over-the-air updates that can be pushed remotely to deployed systems"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"System Monitoring"}),": Continuous tracking of system health and performance metrics"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Containerization"}),": Packaging software and its dependencies into lightweight, portable containers"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Orchestration"}),": Managing and coordinating multiple distributed systems or containers"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"learning-checkpoints",children:"Learning Checkpoints"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement a system integrator that coordinates between perception, planning, and control systems"}),"\n",(0,a.jsx)(n.li,{children:"Create a monitoring system that tracks CPU, memory, and system health"}),"\n",(0,a.jsx)(n.li,{children:"Design a deployment strategy using containers for consistent system deployment"}),"\n",(0,a.jsx)(n.li,{children:"Implement OTA update capabilities with rollback functionality"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Week 12 covered the critical aspects of integrating multiple robotics subsystems into a cohesive system and deploying those systems in real-world environments. We explored system integration patterns, monitoring solutions, and deployment strategies including containerization and OTA updates. These skills are essential for building robust, maintainable Physical AI systems that can operate reliably in production environments."})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>o});var t=s(6540);const a={},r=t.createContext(a);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);